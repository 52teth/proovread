#!/usr/bin/env perl

##------------------------------------------------------------------------##
# LICENCE
#
#
# 
#
##------------------------------------------------------------------------##

use warnings;
use strict;

use Pod::Usage;
use Getopt::Long;

use FindBin qw($RealBin);
use lib "$RealBin/../lib/";

use List::Util;

use Verbose;
use Verbose::ProgressBar;

use Sam::Parser;
use Sam::Alignment ':flags';
use Sam::Seq 0.10;

use Fasta::Parser;
use Fasta::Seq;

use Fastq::Parser;
use Fastq::Seq 0.08;

use constant {
	OFFSET => 0,
	LENGTH => 1,
};

use Storable qw(dclone);

our $VERSION  = '0.07';




=head1 NAME

sam2cns

=cut

=head1 DESCRIPTION

Compute consensus sequences based on SAM file.

=head1 SYNOPSIS

  sam2cns <OPTIONS>

=cut

=head1 CHANGELOG

=cut

=head2 0.07

=over

=item [Refacture] Instead of reading the entire SAM chunk into memory, only
 read entries for read block, create consensus and reuse memory with next
 read block.

=back

=cut

=head2 0.06

=over

=item [BugFix/Refac] C<< --min-lcr-length >> between hcrs was messed up. Refactored
 entire block, twice :).

=item [Feature] C<< lcr-end-ratio >> to control end mask/unmask behaviour.

=item [Feature] Improved masking, ends are either unmasked or masked to the
 last nucleotide if they are too short.

=item [Feature] C<< --mask-weak-reads/--ignore-weak-reads >> to handle 
 bad reads and contaminations more efficiently

=back

=cut

=head2 0.05

=over

=item [BugFix] Only test C<< --max-reads >> if actually set.

=item [BugFix] C<< --min-lcr-length >> defaults to 120 instead of undef.

=item [BugFix] Do not add header to chimera file to make its concatenable.

=item [Feature] sam2cns uses the compressed cigar string from 
 C<< Sam::Seq->consensus >> to exactly project the chimera breakpoints from
 the reference coordinates onto the corrected sequence. These coordinates
 are reported to the chimera coords tsv.

=back

=cut

=head2 0.04

=over

=item [Change] start and end are only unmasked if the missing part is long
 enough.

=item [Feature] prevent read start/end masking within C<< --min-lcr-length >>

=item [Feature] C<< --min-lcr-length >> controls the minimum number of 
 unmasked nts between hcrs. 

=back

=cut

=head2 0.03

=over

=item [Feature] <--append> to add output to already existing file.

=item [Feature] Reference is optional, consensus from SAM only is possible.

=item [Feature] <--ignore-hcr> parameter to toggle HCR evalutation 
 consensus calls.

=item [Change] Removed C<--sticky-end-length> and  C<--hcr-mask-length> 
 parameter from command line options. Are now set via config

=item [Feature] Added <--cfg> to read from custom config

=item [Feature] Reads core config

=item [Change] Uses C<<$FindBin::RealBin>> instead of C<<$FindBin::Bin>>

=back

=cut

=head2 0.02

=over

=item [Renaming] C<$Version> to C<$VERSION>. 

=item [Feature] Added C<$REVISION>.

=item [Change] Requires Fastq::Seq 0.08, C<< fq->clone >> to C<< fq->new >>.

=item [Feature] Added C<--sticky-end-length> parameter.

=back

=cut

=head2 0.01

Initial script.

=cut



##------------------------------------------------------------------------##

# load core defaults
my $cfg_core_file = "$RealBin/../proovread.cfg"; 
my %cfg = do $cfg_core_file;

# custom config
my $cfg;
for(my $i=0; $i<@ARGV; $i++){
	if($ARGV[$i] =~ /-c$|--cfg$/){
		$cfg = $ARGV[$i+1];
		%cfg = (%cfg, do "$cfg"); 
		last;
	}
}

my %opt;

=head1 OPTIONS

=cut

=over 12

=cut

=item --cfg=<STRING>

Config file.

=cut 

$opt{'cfg=s'} = \$cfg;

=item --prefix=<STRING>

Prefix for output files.

=cut 

$opt{'prefix=s'} = \(my $opt_pre = '');

=item --sam=<PATHNAME>

A SAM file, sorted by reference, from which a consensus sequence for each reference sequence
 is to be calculated.

=cut

$opt{'sam=s'} = \(my $opt_sam_file);

=item [--sam-offset=<INT>]

A byte offset at which to start running through the --sam-file.

=cut

$opt{'sam-offset=i'} = \(my $opt_sam_offset);

=item [--ref=<PATHNAME>]

Reference sequences in FASTA or FASTQ format. If FASTQ is provided, detects 
 HCR tags in header description and inlcudes corresponding sequence 
 information in the consensus computation.

=cut

$opt{'ref=s'} = \(my $opt_ref_pat);

=item [--ref-offset=<INT>]

A byte offset at which to start running through the --ref-in file.

=cut

$opt{'ref-offset=i'} = \(my $opt_ref_offset);

=item [--max-reads=<INT>] [0]

Maximum number of reads to correct. Default OFF.

=cut

$opt{'max-reads=s'} = \(my $opt_max_reads = 0);

=item [--coverage=<INT>] [50]

Estimated coverage.

=cut

$opt{'coverage=s'} = \(my $opt_cov = 50);

=item [--qv-offset=<INT>] [33]

Quality offset.

=cut

$opt{'qv-offset=s'} = \(my $opt_qv_offset = 33);

=item [--ignore-hcr] [OFF]

Boolean. Do not parse and use HCRs from reference file in consensus calls.

=cut

$opt{'ignore-hcr'} = \(my $opt_ignore_hcr);

=item [--[no]detect-chimera] [OFF]

Boolean. Dectect, tag, and if possible resolve chimeric sequences.

=cut

$opt{'detect-chimera!'} = \(my $opt_detect_chimera);

=item [--append] [OFF]

Append output if output file already exists

=cut

$opt{'append!'} = \(my $opt_append);

=item [--sr-min-length=<INT>] [100]

Minimal expected short read length.

=cut

$opt{'sr-min-length=s'} = \(my $opt_sr_min_length = 100);

=item [--lcr-min-ratio=<FLOAT>] [.cfg]

Minimum length of unmasked nts between hcrs w/r/t --sr-min-length

=cut

$opt{'lcr-min-ratio=s'} = \(my $opt_lcr_min_ratio = $cfg{'lcr-min-ratio'});

=item [--lcr-end-ratio=<FLOAT>] [.cfg]

End mask/unmasked threshold. Read ends are either masked completely or 
 unmasked to --min-sr-length to allow new mappings. The value specifies the
 proportions of --min-lcr-length required to unmask the end.

=cut

$opt{'lcr-end-ratio=s'} = \(my $opt_lcr_end_ratio = $cfg{'lcr-end-ratio'});

=item [--hcr-min-ratio=<FLOAT>] [.9]

Minimum length of masked nts in hcrs

=cut

$opt{'hcr-min-ratio=s'} = \(my $opt_hcr_min_ratio = $cfg{'hcr-min-ratio'});

=item [--hcr-sticky-ratio=<FLOAT>] [.4]

Unmask this much at the ends of every hcr. Cannot be bigger then 
 --hcr-min-ratio/2.
 
=cut

$opt{'hcr-sticky-ratio=s'} = \(my $opt_hcr_sticky_ratio = $cfg{'hcr-sticky-ratio'});


=item [--max-ins-length=<INT>] [4]

Maximum allowed length for inserts.

=cut

$opt{'max-ins-length=i'} = \(my $opt_max_ins_length = 4);

=item [--mask-weak-reads=<INT>] [20]

=cut

$opt{'mask-weak-reads=i'} = \(my $opt_mask_weak_reads = 20);

=item [--ignore-weak-reads=<INT>] [20]

Simple do not generate consensus for weakly supported reads, output them 
 unprocessed.

=cut

$opt{'ignore-weak-reads=i'} = \(my $opt_ignore_weak_reads = 20);


$opt{'chimera-min-score'} = \(my $opt_chimera_min_score = 0);

=back

=cut







##------------------------------------------------------------------------##

=head1 MAIN

=cut

GetOptions(%opt) or pod2usage(1);
$opt_sam_file || pod2usage(msg => 'SAM file required');


my $v = Verbose->new();

# init sam parser
my $sp = Sam::Parser->new(
	file => $opt_sam_file,
);

# process ratios to abs

my $hcr_sticky_length = 0;
if($opt_hcr_min_ratio){
	$v->exit('--hcr-min-ratio needs to be at least twice as big as hcr-sticky-ratio') if ($opt_hcr_sticky_ratio*2 >= $opt_hcr_min_ratio);
	$hcr_sticky_length = int($opt_hcr_sticky_ratio * $opt_sr_min_length +0.5);
}
my $hcr_min_length = int($opt_hcr_min_ratio * $opt_sr_min_length +0.5) || 0;

my $lcr_min_length = int($opt_lcr_min_ratio * $opt_sr_min_length +0.5) || 0;


Sam::Seq->Trim($cfg{'sr-trim'});
Sam::Seq->InDelTaboo($cfg{'sr-indel-taboo'});
Sam::Seq->MaxCoverage($opt_cov);
Sam::Seq->BinSize($cfg{'bin-size'});
Sam::Seq->MaxInsLength($opt_max_ins_length);

Fastq::Seq->Qual_lcs_range(5, 41, $opt_qv_offset);  
## 80 chars are cutoff at each side to keep overlaps => min length 160, better 200
Fastq::Seq->Qual_lcs_min_length($hcr_min_length + (2 * $hcr_sticky_length)); 

# qual window
Fastq::Seq->Qual_window_min(3);  


# use glob, to allow glob pattern instead of full filename (fa/fq is decided by parser)
my $opt_ref_file;
my $rpr;

if($opt_ref_pat){
	($opt_ref_file) = glob($opt_ref_pat);
	$v->exit("Reference file not found ($opt_ref_pat)") unless $opt_ref_file;
	# init fastq/fasta parser
	$rpr = Fastq::Parser->new(file => $opt_ref_file)->check_format;
	if($rpr){
		my $po = $rpr->guess_phred_offset();
		$v->exit("Detected [$po] and specified [$opt_qv_offset] phred offsets differ!") if defined ($opt_qv_offset) && defined ($po) && $po != $opt_qv_offset;
		$po = $po || $opt_qv_offset;
		$v->exit("Cannot guess phred offset from provided reference file, please specify --qv-offset")
			unless $po;
		$rpr->phred_offset($po);
		
	}else{
		$rpr = Fasta::Parser->new(file => $opt_ref_file)->check_format;
		unless ($opt_ignore_hcr){
			$opt_ignore_hcr++;
			# $v->verbose('Cannot restore HCR information from FASTA, --ignore-hcr set to TRUE');
		}
	}
	$v->exit("Unknown format of reference file: $opt_ref_file") unless $rpr;
}

# output files
my $fq_out =  $opt_pre.'.fq';
my $fam_out = $opt_pre.'.masked.fa';
my $fqi_out = $opt_pre.'.ignored.tsv'; # ignored
my $fc_out =  $opt_pre.'.chim.tsv'; # chimera annot

my $mode = $opt_append ? ">>" : ">";

my $fqh;
open($fqh, $mode, $fq_out) || $v->exit("Can't open output read file: '$fq_out'");
my $fmh;
open($fmh, $mode, $fam_out) || $v->exit("Can't open output read file: '$fam_out'");
my $fih;
open($fih, $mode, $fqi_out) || $v->exit("Can't open output read file: '$fqi_out'");
my $fch;
open($fch, $mode, $fc_out) || $v->exit("Can't open output read file: '$fc_out'");
#print $fch (join("\t", '#id', qw(from to score)),"\n") if ! -s $fch;




# DEPRECATED
# ref
#my %LR;
#if($rpr){ # read fasta to get ref id, length and seq
#	$rpr->seek($opt_ref_offset) if $opt_ref_offset;
#	my $ref_c = 0;
#	while(my $ref = $rpr->next_seq()){
#		$LR{$ref->id} = Sam::Seq->new(
#			ref => $ref,
#			len => length($ref->seq),
#			id => $ref->id
#		);
#		last if ++$ref_c >= $opt_max_reads;
#	}
#}else{# read the sam header to get ref ids and length
#	while(my %h = $sp->next_header_line('SQ')){
#		$LR{$h{'SN'}} = Sam::Seq->new(
#			id => $h{SN}, 
#			len => $h{LN},
#		);
#	}
#}
#####

#### PROBLEM ####
# how to track that there are reads, that do not show in SAM file if ref
# is provided
# sort @LR_IDS, expect each to be in SAM
# get a list of ref (seqs) ids and len

my %LR;
my @LR_IDS;

if($rpr){ # read fasta to get ref id, length and seq
	$rpr->seek($opt_ref_offset) if $opt_ref_offset;
	my $ref_c = 0;
	while(my $ref = $rpr->next_seq()){
          $LR{$ref->id} = {
			ref => $ref,
			len => length($ref->seq),
			id => $ref->id
		};
		push @LR_IDS, $ref->id;	
          	last if $opt_max_reads && ++$ref_c >= $opt_max_reads;

	}
}else{# read the sam header to get ref ids and length
	while(my %h = $sp->next_header_line('SQ')){
		$LR{$h{'SN'}} = {
			id => $h{SN}, 
			len => $h{LN},
		};
	}
}

@LR_IDS = sort byfile @LR_IDS;

#  jump to sam ref pos
$sp->seek($opt_sam_offset) if $opt_sam_offset;

my $ref_seen = 0; # since we read the entire header to %LR, we need to count ref seqs
my $ref_id = '';
my $sso;

while(my $aln = $sp->next_aln()){
	# new block
	unless ($ref_id eq $aln->rname){
		# process previous block
		if ($ref_id){
			generate_consensus($sso);
			$ref_seen++;
		};
		
		$ref_id = $aln->rname;
		
		# test whether new read_id is also next in @LR_IDS
		while($ref_seen < @LR_IDS && $LR_IDS[$ref_seen] ne $ref_id){
			# unmapped seq needs to be outputted as well
			generate_consensus(
				Sam::Seq->new(
					id => $LR{$LR_IDS[$ref_seen]}{id},
					len => $LR{$LR_IDS[$ref_seen]}{len},
					ref => $rpr ? $LR{$LR_IDS[$ref_seen]}{ref} : undef,
				)
			);
			$ref_seen++;
		};

		# max read condition
		if ($opt_max_reads && $ref_seen >= $opt_max_reads){
			$sso = undef;
			last 
		};

		# create new block with $aln = first entry
		$sso = Sam::Seq->new(
			id => $LR{$ref_id}{id},
			len => $LR{$ref_id}{len},
			ref => $rpr ? $LR{$ref_id}{ref} : undef,
		);
	}
	
	# process aln
	$opt_detect_chimera		# binning required for chimera detection
		? $sso->add_aln_by_score($aln)
		: $sso->add_aln($aln);
}

# process eof block if existing
if($sso){
	generate_consensus($sso);
	$ref_seen++;
};

# test whether new read_id is also next in @LR_IDS
while($ref_seen < @LR_IDS && $LR_IDS[$ref_seen] ne $ref_id){
	# unmapped seq needs to be outputted as well
	generate_consensus(
		Sam::Seq->new(
			id => $LR{$LR_IDS[$ref_seen]}{id},
			len => $LR{$LR_IDS[$ref_seen]}{len},
			ref => $rpr ? $LR{$LR_IDS[$ref_seen]}{ref} : undef,
		)
	);
	$ref_seen++;
};








=head2 generate_consensus

Takes a Sam::Seq object, creates, processes and outputs consensus

=cut

sub generate_consensus{
	my $sso = shift; # Sam::Seq object
	print shift if @_;
	my @hcrs = ();
	
	if($rpr && ! $opt_ignore_hcr){
		if(my $hcrs = $sso->ref->desc){
			while($hcrs =~ /HCR\d+:(\d+),(\d+)/g){
				push @hcrs, [$1, $2];
			}
		};
	}
	
	if(! @hcrs){
		if(
			($opt_mask_weak_reads && $sso->{_aln_idc} < $opt_mask_weak_reads)
			|| ($opt_ignore_weak_reads && $sso->{_aln_idc} < $opt_ignore_weak_reads)
		){
			my $seq = $sso->ref;
			unless (ref $seq eq "Fastq::Seq"){
				$seq = Fastq::Seq->new(
					substr($seq->seq_head, 1),
					$seq->seq,
					'+',
					'!' x length ($seq->seq),
					phred_offset => 33,
				);
			}else{
				$seq->qual('!' x length ($seq->seq)),
			}
			
			
			unless ($seq->desc() =~ /IGNORED:low_support/){
				$seq->desc_append("IGNORED:low_support"); 
				# write to ignored fastq
				printf $fih "%s\t%s\n", $seq->id, "low_support";
			}
			
			# write unprocessed fastq
			print $fqh "$seq";
			
			# write masked/unprocessed fasta
			printf $fmh (">%s\n%s\n", substr($seq->seq_head, 1), 
				$opt_mask_weak_reads ? "N" x length($seq->seq) : $seq->seq);

			return;
		}
	}
	
	my $con = $sso->consensus(@hcrs);
	
	# chimera
	if($opt_detect_chimera){
		my @coords = $sso->chimera(); 
		
		#-----------------------------------------------------------------#
		#my %cigar = (M=>0, I=>0, D=>0);
		#while($con->{cigar} =~ m/(\d+)(\w)/g){
		#	$cigar{$2}+=$1;
		#}
		#my $pred_len = $cigar{M}+$cigar{D};
		#my $corr_len = length($LR{$pb_id}{ref}->seq)+$cigar{D}-$cigar{I};
		#printf("%s\t%s\t%s\n", length($con->seq), $pred_len, $corr_len) if $pred_len !=  $corr_len or length($con->seq) != $corr_len;
		#
		#-----------------------------------------------------------------#
		
		
		if(@coords){
			my $i;
			my %cigar = (M=>0, I=>0, D=>0);
			for($i=0; $i<@coords; $i++){
				
				my $fr = $coords[$i]{col_range}[0];
				my $to = $coords[$i]{col_range}[1];
				my $sc = $coords[$i]{score};
				
				# use cigar to compute correct location of chimera coords on corrected seq.
				# -I, +D
				# get read cigar, eg 80M2D3M1IM4
				# /g remembers position even between multiple calls to while on same cigar
				# hence we can just always add to %cigar outside the for loop
				while($con->{cigar} =~ m/(\d+)(\w)/g && ($cigar{M}+$cigar{I} < $fr)){ 
					$cigar{$2}+=$1;
				}
				
				my $pos_corr = $cigar{D}-$cigar{I}; # corrected string has additional nucs
					# at D's and has lost nucs at I's
				$fr+=$pos_corr;
				$to+=$pos_corr;

				if($to > length($con->seq)){
					use Data::Dumper;
					die "Chimera Breakpoint outside of sequence", Dumper({
						cigar => \%cigar,
						poscorr => $pos_corr,
						conlen => length ($con->seq),
						concigar => $con->{cigar},
						reflen => length ($sso->ref->seq),
						coords => $coords[$i],
					});
				};

				printf $fch("%s\t%d\t%d\t%s\n", $sso->id, $fr, $to, $sc);
			}
		}
	}
	
	# undef state matrix to make memory availabe again
	$sso->{_state_matrix} = {}; 

	if($hcr_min_length){
		# $hcrs[$i][0] == $hcrs[$i][OFFSET] := offset
		# $hcrs[$i][1] == $hcrs[$i][LENGTH] := length
		
		# clone
		my $con_mask = $con->new;
		# compute high coverage regions 
		my @hcrs = ($con_mask->qual_lcs());
		if(@hcrs){
			my $hcr_c = 0;
			# create a description string of hcrs in seq
			my @hcrs_string = map{"HCR".++$hcr_c.":".$_->[OFFSET].','.$_->[LENGTH]}@hcrs;
			# add desc to header
			$con->{seq_head}.= ' '.join(" ", @hcrs_string);

			#hcr sticky
			foreach(@hcrs){
				$_->[OFFSET]+=$hcr_sticky_length; 
				$_->[LENGTH]-=($hcr_sticky_length * 2);
			}	
			
			#head
			# mask/unmask start
			my $seq_length = length($con_mask->seq);
			my $lcr_start_short = $lcr_min_length - $hcrs[0][OFFSET];
			# Consider starts shorter then lcr_min_length
			if($lcr_start_short > 0){
				# unmask start if its long enough to be worth it: short < 50% lcr_min_length
				if( $lcr_start_short < $opt_lcr_end_ratio * $lcr_min_length ){ 
					#$v->hline;
					#$v->verbose('first hcr to close to start '.$lcr_start_short);
					# if OFFSET is adjusted, LENGTH always needs to be adjusted
					#  as well or the HCR is just shifted
					# adjust length, check for hcr_min_length
					if( ($hcrs[0][LENGTH] -= $lcr_start_short) < $hcr_min_length){
						#$v->verbose('first hcr to short: '.$hcrs[0][LENGTH]);
						shift @hcrs; # remove first hcr if it becomes to short after trimming
					}else{
						#$v->verbose('first hcr trimmed');
						$hcrs[0][OFFSET] += $lcr_start_short;
					}
				}else{# mask start completely
					$hcrs[0][LENGTH] += $hcrs[0][OFFSET];
					$hcrs[0][OFFSET] = 0;
				}
			} 
			
			# mask/unmask end
			if( scalar @hcrs ){ # check if there are HCRs, might be trimmed by first
				my $lcr_end_short = $lcr_min_length - ($seq_length - ($hcrs[$#hcrs][OFFSET] + $hcrs[$#hcrs][LENGTH]));
				# check if it is to close to the end
				if($lcr_end_short  > 0){
					if($lcr_end_short < $opt_lcr_end_ratio * $lcr_min_length ){
						#$v->verbose('last hcr to close to end '.$lcr_end_short);
						# shorten last hcr and check its length
						if( ($hcrs[$#hcrs][LENGTH] -= $lcr_end_short) < $hcr_min_length){
							#$v->verbose('last hcr to short');
							pop @hcrs; # remove last hcr if it becomes to short after trimming
						}
					}else{# extend hcr to end of seq
						$hcrs[$#hcrs][LENGTH] += $lcr_min_length - $lcr_end_short
					}
				}
			} 
			
			# precompute changes
			my $cc=0;
			while( @hcrs ){
				#print "#- hcr trimming cycle ", ++$cc, " --#\n";
				# create temporary hash structure with indexes as keys
				my %hcrs;
				my @hcrs_short_idx;
				# DEEEEP COPY REQUIRED !!!!!!!!!!
				my @tmp_hcrs = @{dclone(\@hcrs)};
				@hcrs{0..$#hcrs} = @tmp_hcrs;
				# find + extend short hcrs
				# + cache short hcr idxs
				my $i=0;
				for(;$i<$#hcrs;$i++){
					# compute gap to next
					my ($ha, $hb) = ($hcrs{$i}, $hcrs{$i+1});
					my $hae = $ha->[OFFSET]+$ha->[LENGTH];
					my $hbs = $hb->[OFFSET];
					if((my $lcr_short = $lcr_min_length - ($hbs - $hae)) > 0){
						my $lcr_short_a = int($lcr_short/2);
						my $lcr_short_b = $lcr_short_a + $lcr_short%2; 
						$ha->[LENGTH] -= $lcr_short_a;
						if( $ha->[LENGTH] < $hcr_min_length ){ # $ha is completely processed
							push @hcrs_short_idx, $i 
						}
						$hb->[OFFSET] += $lcr_short_b;
						$hb->[LENGTH] -= $lcr_short_b;
					}
				}
				# and dont forget the last hcr length
				if( $hcrs{$i}[LENGTH] < $hcr_min_length ){ # $ha is completely processed
					push @hcrs_short_idx, $i 
				}
				
				# skip longer adjacent
				my @hcrs_short_idx_clean;
				foreach (@hcrs_short_idx){
					unless(@hcrs_short_idx_clean){
						push @hcrs_short_idx_clean, $_
					}elsif( $_ -1 == $hcrs_short_idx_clean[-1] ){ # adjacent
						# compare lengths
						if($hcrs{$_}[LENGTH] < $hcrs{$hcrs_short_idx_clean[-1]} ){
							# prev was longer, remove from clean, push new
							pop @hcrs_short_idx_clean;
							push @hcrs_short_idx_clean, $_;
						}
						# else do nothing -> skip
					}else{ # non adjacent
						push @hcrs_short_idx_clean, $_
					}
				}
				
				# all conflicting hcrs/lcrs trimmed
				unless(@hcrs_short_idx_clean){
					@hcrs = @tmp_hcrs;
					last;
				};
				
				# remove unmodified hcrs before next cycle
				foreach (@hcrs_short_idx_clean){
					splice(@hcrs, $_, 1);
				}
			}

	
=pod DEPRECATED			
			my $i = 0;
			# create a description string of hcrs in seq
			my @hcrs_string = map{"HCR".++$i.":".$_->[OFFSET].','.$_->[LENGTH]}@hcrs;
			# add desc to header
			$con->{seq_head}.= ' '.join(" ", @hcrs_string);
			# mask hcrs minus overlap ends
			# NOTE: this actually changes the values @hcrs!
			
			# add sticky ends
			foreach(@hcrs){
				$_->[OFFSET]+=$hcr_sticky_length; 
				$_->[LENGTH]-=($hcr_sticky_length * 2);
			}			
			
			# mask/unmask start
			my $lcr_start_missing = $lcr_min_length - $hcrs[0][OFFSET];
			# Consider starts shorter then lcr_min_length
			if($lcr_start_missing > 0){
				# unmask start if its long enough to be worth it: missing < 50% lcr_min_length
				if( $lcr_start_missing < $lcr_end_ratio * $lcr_min_length ){ 
					#$v->hline;
					#$v->verbose('first hcr to close to start '.$lcr_start_missing);
					# if OFFSET is adjusted, LENGTH always needs to be adjusted
					#  as well or the HCR is just shifted
					# adjust length, check for hcr_min_length
					if( ($hcrs[0][LENGTH] -= $lcr_start_missing) < $hcr_min_length){
						#$v->verbose('first hcr to short: '.$hcrs[0][LENGTH]);
						shift @hcrs; # remove first hcr if it becomes to short after trimming
					}else{
						#$v->verbose('first hcr trimmed');
						$hcrs[0][OFFSET] += $lcr_start_missing;
					}
				}else{# mask start completely
					$hcrs[0][LENGTH] += $hcrs[0][OFFSET];
					$hcrs[0][OFFSET] = 0;
				}
			} 
			
			# mask/unmask end
			if( scalar @hcrs ){ # check if there are HCRs, might be trimmed by first
				my $lcr_end_missing = $lcr_min_length - (length($con_mask->seq) - ($hcrs[$#hcrs][OFFSET] + $hcrs[$#hcrs][LENGTH]));
				# check if it is to close to the end
				if($lcr_end_missing  > 0){
					if($lcr_end_missing < $lcr_end_ratio * $lcr_min_length ){
						#$v->verbose('last hcr to close to end '.$lcr_end_missing);
						# shorten last hcr and check its length
						if( ($hcrs[$#hcrs][LENGTH] -= $lcr_end_missing) < $hcr_min_length){
							#$v->verbose('last hcr to short');
							pop @hcrs; # remove last hcr if it becomes to short after trimming
						}
					}else{# extend hcr to end of seq
						$hcrs[$#hcrs][LENGTH] += $lcr_min_length - $lcr_end_missing +1
					}
				}
			} 
			
			# make sure unmask regions are large enough to map more reads
			my @keep_hcrs;

			if( scalar @hcrs){ # check if there are HCRs, might be trimmed by first
				my ($ha, $hb) = shift @hcrs;
				while($hb = shift @hcrs){
					my $hbs = $hb->[OFFSET]; # start
					my $hae = $ha->[OFFSET] + $ha->[LENGTH]; # end
					
					# lcr to short
					if( (my $lcr_min_missing = $lcr_min_length - ($hbs - $hae)) > 0 ){
						# what if adjusted both length
						my $hal = $ha->[LENGTH] - $lcr_min_missing/2;
						my $hbl = $hb->[LENGTH] - $lcr_min_missing/2;
						if($hbl < $hcr_min_length){ # hb short
							# ha stays ha unchanged, hb isnt kept, but overwritten
							next;
						}elsif($hal < $hcr_min_length){ # ha short
							$ha=$hb; # set hb to new ha, unchanged, dont keep ha
							next; # restart cycle
						}else{ # both long enough
							# make the changes
							$ha->[LENGTH] -= $lcr_min_missing/2;
							
							$hb->[OFFSET] += $lcr_min_missing/2;
							$hb->[LENGTH] -= $lcr_min_missing/2;
							
							push @keep_hcrs, $ha; # store ha
							$ha=$hb; # set hb to new ha
							next; # restart cycle
						}
					}else{
						# nothing missing
						push @keep_hcrs, $ha;
						$ha=$hb;
					}
				}	

				# process last hcr, now ha
				if( $ha->[LENGTH] >= $hcr_min_length ){
					push @keep_hcrs, $ha;
				}
			}
=cut



			$con_mask->mask_seq(@hcrs) if @hcrs;
		}
	
		# write (masked) FASTA for next pass
		printf $fmh (">%s\n%s\n", substr($con->seq_head, 1), $con_mask->seq);
	}
	
	# write current fastq
	print $fqh "$con";
	
}


=head2 byfile

Sort function for "natural" filesorting, descending.

=cut

sub byfile{
  my @a = split /(\d+)/, $a;
  my @b = split /(\d+)/, $b;
  my $M = @a > @b ? @a : @b;
  my $res = 0;
  for (my $i = 0; $i < $M; $i++) {
    return -1 if ! defined $a[$i];
    return 1 if  ! defined $b[$i];
    if ($a[$i] =~ /\d/) {
      $res = $a[$i] <=> $b[$i];
    } else {
      $res = $a[$i] cmp $b[$i];
    }
    last if $res;
  }
  $res;
}

=head1 AUTHORS

Thomas Hackl S<thomas.hackl@uni-wuerzburg.de>

=cut
