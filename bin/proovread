#!/usr/bin/env perl

##------------------------------------------------------------------------##
# LICENCE
#
#
# $Id$
#
##------------------------------------------------------------------------##

use warnings;
use strict;

use Getopt::Long;
use Pod::Usage;
use List::Util qw(sum max);

use File::Basename;
use File::Path qw(make_path remove_tree);
use File::Copy;
use FindBin qw($RealBin);

use Data::Dumper;

use lib "$RealBin/../lib/";

use Verbose;
use Verbose::ProgressBar;

use Fastq::Parser '0.07';
use Fastq::Seq;

use Fasta::Parser '0.08';
use Fasta::Seq;

use Sam::Parser;
use Sam::Alignment;
use Sam::Seq '0.08';

use Shrimp;


our $VERSION = '0.72';
our ($REVISION) = '$Revision$' =~ /(\d+)/;
our ($MODIFIED) = '$Date$' =~ /Date: (\S+\s\S+)/;


=head1 NAME

proovread

=cut

=head1 DESCRIPTION

Correct single molecule sequencing reads by iterative mapping of high
 throughput sequencing reads.

=cut

=head1 CHANGELOG


=head2 0.72

=over

=item [Feature] Added C<sr-trim> and C<sr-indel-taboo-length> to advanced
 config options

=item [Change] Uses Sam::Seq 0.08, which provides InDelTabooLength based 
 short read trimming to reduce errors especially in edge regions

=item [Change] Binary path is now determined by $FindBin::Realbin instead of
 $FindBin::Bin. Robust against linking the binary.

=item [Feature] Read short reads FASTA input

=item [Change] remove_tree moved to END{}, to delete folders also in case of 
 an error

=item [BugFix] Bad rounding, $pg_step could become 0, does not work in modulus

=back

=head2 0.71

=over

=item [Feature] Test config file for existence before loading.

=item [Feature] proovread now reads all parameter from a default core config
 (proovread.cfg). Additionally an optional, customized config file can be
 generated for user modification C<< --create-cfg >> and the modified config
 can be provided to the pipeline with C<< -c/--cfg >>. Highest controll 
 priority remains with the scripts command line parameter, yet the configs 
 manipulate the defaults and allow additional advanced settings, like shrimp
 mapping parameter, which cannot be controlled via command line. 

=back

=head2 0.70

=over

=item [Feature] Shrimp progress bar now displays to actual precentage of 
 mapped reads und computes ETA, using the --sr-count guess and on the fly
 parsing of the Shrimp progress from the Shrimp log file.

=item [Feature] "--sr-count" with auto-guess, used for eta calculations.

=item [Feature] "--sr-length" with auto-guess.

=item [Feature] "--sr-qv-offset" with auto-guess.

=item [Renaming] "--qv-offset" to "--sr-qv-offset" 

=item [Renaming] "--reads" to "--short-reads" and "--ref" to "--long-reads"

=item [Change] C<--qv-offset> is now required without default. 

=item [Change] Rearranged parameter specs, removed parameter currently not working/under
 development.

=item [Renaming] <reads> variables to <sr>, <ref> to <lr>.

=item [Change] Default C<--full-threshold> to 55%,35%.

=item [Change] Reduced gap extension costs for shrimp by one to prevent 
 misalignments of Triplet/... insertions in variants and to account
 for slight bias towards homopolymer errors.

=back

=head2 0.60

=over

=item [Bugfix] --reads did not recycle value, if only one set was given and 
 multiple passes are run.

=item [Refactoring] Versionized.

=back

=cut

=head1 TODO

=over

=item hcr-masked and hcr-unmasked output

=item masking stats -> FastaFilter

=item 1-3 passes

=back

=cut

##------------------------------------------------------------------------##

my $no_error;

# verbose
my $v = Verbose->new(
	format => "[{TIME_FULL}] {MESSAGE}\n",
);

# verbose bash style
my $vb = Verbose->new(
	line_delim => "\\\n",
	line_width => 80,
	format => "{MESSAGE}\n",
);

$v->verbose("Running $0-$VERSION, rev$REVISION, $MODIFIED");


=head1 OPTIONS

=cut

=over

=cut

# load core defaults
$v->verbose("Reading core config");
my $cfg_core_file = "$RealBin/../proovread.cfg"; 
my %cfg = do $cfg_core_file;

=item [--create-cfg=<CFGFILENAME>] [<CWD>/proovread_cfg.pm]

Create a custom config file. Unless you provide a PATHNAME, defaults to 
 CWD/proovread.cfg. Does not run the pipeline. The custom config file 
 can be modified/renamed and supplied to the pipeline using -c/--cfg. The
 config file is optional, supercedes default parameters, but has lower 
 priority than command line options. The config fall also allows control
 of advanced options, not available via command line. For details, create
 a config file and have a look at its header section.

=item [-c, --cfg]

Custom config file.

=cut

# load user defaults and overwrite core
my $cfg;
for(my $i=0; $i<@ARGV; $i++){
	if($ARGV[$i] =~ /--create-cfg$/){
		my $cfg_custom_file = $i < $#ARGV ? $ARGV[$i+1] : basename($cfg_core_file);
		$v->verbose("Creating custom config file: $cfg_custom_file");
		copy_custom_cfg($cfg_core_file, $cfg_custom_file);
		exit(0);
	}
	if($ARGV[$i] =~ /-c$|--cfg$/){
		$cfg = $ARGV[$i+1];
		last;
	}
}

if($cfg){
	unless(-e $cfg){
		$v->exit("Cannot find config file: $cfg");
	}
	$v->verbose("Reading custom config: $cfg");
	%cfg = (%cfg, do "$cfg"); 
}

$v->verbose("Reading command line options");

# load cmd options and overwrite defaults
my %opt;

$opt{'c|cfg=s'} = \$cfg;

=item -l, --long-reads=<PATHNAME>

Pacbio reads to correct. FASTA or FASTQ format.

=cut

$opt{'l|long-reads=s'} = \(my $opt_lr_file = $cfg{'long-reads'});

=item -s, --short-reads=<PATHNAME>

High confidence short reads used for correction in FASTQ format.
 Either one set of reads for all passes or a comma separated list, 
 one value for each pass.

=cut

$opt{'s|short-reads=s'} = \(my $opt_sr_file = $cfg{'short-reads'});

=item [-p, --prefix=<STRING>]

Prefix to output files. Defaults to <CWD>/<SHORTREADS#LONGREADS> or
 <CWD>/<SAM>, respectively.

=cut

$opt{'p|prefix=s'} = \(my $opt_prefix = $cfg{'prefix'});

=item [--coverage=<INT>] [50]

Coverage cutoff for highest scoring mappings at each location.

=cut

$opt{'coverage=s'} = \(my $opt_cov = $cfg{'coverage'});

=item [-t, --threads] [8]

Number of threads to use for mapping. Defaults to 8 (or maximum available 
 number of processors, if kess than 8 availabe).

=cut

$opt{'t|threads=i'} = \(my $opt_threads = $cfg{'threads'});

=item [--sr-qv-offset] [auto-guess]

Short read quality offset, usually 64 or 33, use 0 for FASTA. Defaults to 
 guessing, taking into account the first 100 reads of the file. Specify 
 value if guessing fails.

=cut

$opt{'sr-qv-offset=i'} = \(my $opt_sr_qv_offset = $cfg{'sr-qv-offset'});

=item [--sr-length] [auto-guess]

Short read length. Defaults to guessing, taking into account the first 100
 reads of the file. Specify value if guessing fails.

=cut

$opt{'sr-length=i'} = \(my $opt_sr_length = $cfg{'sr-length'});

=item [--sr-count] [auto-guess]

Number of short reads provided, used for ETA calculation. Defaults to 
 guessing, taking into account the first 100 reads of the file. Specify 
 value if guessing fails.

=cut

$opt{'sr-count=i'} = \(my $opt_sr_count = $cfg{'sr-count'});

=item [--ram-sam] [OFF]

By default, while mapping, a temporary SAM file is created and an index to
 this file is kept in store. This limits the memory requirement for one SMRT
 cell (>100Mbp, 50X coverage) to less than 10Gb. 

Specify '--ram-sam' to hold the SAM presentation entirely in memory. This is
 faster and saves disk space, but might require up to 100GB per SMRT cell. 

=cut

$opt{'ram-sam'} = \(my $opt_ram_sam = $cfg{'ram-sam'});

=item [--raw-sam] [OFF]

Do not process shrimp output on-the-fly, but create a raw sam file
 and parse this file. Use this for small genomes, where one SMRT
 Cell covers the genome more than 1X. Otherwise the mapper is 
 thwarted by the parser.

=cut

$opt{'raw-sam'} = \(my $opt_raw_sam = $cfg{'raw-sam'});

=item [--sort-sam-by-coordinates] [OFF]

Sort the filtered SAM files by coordinates in addition to the 
 sorting of references. This has no effect on the pipeline, just 
 a convenience if you need the files for something else.

=cut

$opt{'sort-sam-by-coordinates'} = \(my $opt_sort_sam_by_coords = $cfg{'sort-sam-by-coordinates'});

=item [--keep-temporary-files] [OFF]

Specify once, to keep temporary file of each pass, twice to also keep the
 individual temporary file of each thread.

=cut

$opt{'keep-temporary-files+'} = \(my $opt_keep = $cfg{'keep-temporary-files'});


=item [-h, --help]

Show this help.

=cut

$opt{'h|help'} = \(my $opt_help);

=back

=cut


##------------------------------------------------------------------------##

=head1 DEVEL OPTIONS

=cut

=over

=cut

# shrimp:$PASS param
#=item [-f, --full-threshold=<STRING>] [55%,35%]
#
#Shrimp SW Full Hit Threshold. Comma separated, one value for each pass.
#
#=cut
#
#$opt{'f|full-threshold=s'} = \(my $opt_full_threshold = $cfg{'full-threshold'});

=item [--chunk-size] [100]

Number of reads to check out at once for individual correction 
 process.

NOTE: Affects correction, does not affect shrimp.

=cut

$opt{'chunk-size=i'} = \(my $opt_chunk_size = $cfg{'chunk-size'});

=item [--passes=<INT>] [2]

Number of passes.

=cut

$opt{'passes=i'} = \(my $opt_passes = $cfg{'passes'});

=item [--sam=<SAM>]

Use an already created SAM file to create corrected sequences instead of 
 mapping reads to the raw pacbio reads.
 
=cut

$opt{'sam=s'} = \(my $opt_sam_file = $cfg{'sam'});

=item [--coverage-tables] [FALSE]

Calculate and output exact coverage by score tables.

=cut

$opt{'coverage-tables!'} = \(my $opt_cov_tables = $cfg{'coverage-tables'});

=back

=cut

##------------------------------------------------------------------------##


# parse options, test files
GetOptions(%opt) or pod2usage(1);
$opt_help && pod2usage(1);
$opt_sam_file || ($opt_lr_file && $opt_sr_file) || pod2usage("Either --long-reads and --short-reads or --sam required");
$opt_sam_file && ! -f $opt_sam_file && pod2usage("Cannot find $opt_sam_file");
$opt_lr_file && ! -f $opt_lr_file && pod2usage("Cannot find $opt_lr_file");

# sr file
$opt_sr_file && ! -f $opt_lr_file && pod2usage("Cannot find $opt_lr_file");

# test if short reads are FASTQ/FASTA
my $fp;
if($fp = Fastq::Parser->new(file => $opt_sr_file)->check_format){ # FASTQ
	$v->verbose("Detected FASTQ format for --short-reads $opt_sr_file");
	unless (defined $opt_sr_length){
		my ($opt_sr_length, $opt_sr_length_dev) = $fp->guess_seq_length;
		$v->verbose(sprintf("Guessing short read length: %d +-%d", $opt_sr_length, $opt_sr_length_dev ));
		if($opt_sr_length > 500){
			$v->exit(
				"Estimated short reads length > 500\n"
				."Are you sure you specified the correct data? "
				."To run the pipeline on this data, which by design is not really suited, "
				."you need to explicitly provide their mean length as parameter --sr-length"
			);
		}
	}
	unless (defined $opt_sr_qv_offset){
		$opt_sr_qv_offset = $fp->guess_phred_offset; 
		$v->verbose(sprintf("Guessing short read quality offset: %d", $opt_sr_qv_offset));
	}
	unless (defined $opt_sr_count){
		$opt_sr_count = $fp->guess_seq_count();
		$v->verbose(sprintf("Guessing approx number of short reads: %s", Verbose->Humanize($opt_sr_count)));
	}
}elsif($fp = Fasta::Parser->new(file=> $opt_sr_file)->check_format){ # FASTA
	$v->verbose("Detected FASTA format for --short-reads $opt_sr_file");
	unless (defined $opt_sr_length){
		my ($opt_sr_length, $opt_sr_length_dev) = $fp->guess_seq_length;
		$v->verbose(sprintf("Guessing short read length: %d +-%d", $opt_sr_length, $opt_sr_length_dev));
		if($opt_sr_length > 500){
			$v->exit(
				"Estimated short reads length > 500\n"
				."Are you sure you specified the correct data? "
				."To run the pipeline on this data, which by design is not really suited, "
				."you need to explicitly provide their mean length as parameter --sr-length"
			);
		}
	}
	unless (defined $opt_sr_count){
		$opt_sr_count = $fp->guess_seq_count();
		$v->verbose(sprintf("Guessing approx number of short reads: %s", Verbose->Humanize($opt_sr_count)));
	}
}else{
	$v->exit("Short read file $opt_sr_count neither FASTQ nor FASTA format");
}


##------------------------------------------------------------------------##

# globals
my %PB;
my @PB_IDS;
my $PASS;
my $PG_line;
my $PASS_0_suffix;

##------------------------------------------------------------------------##

my $params = "Parameter:";
foreach(sort keys %opt){
	$params.= sprintf("\n\t%s => %s", $_, defined(${$opt{$_}}) ? ${$opt{$_}} : 'undef' );
}
$v->verbose($params);

# read files
my @opt_sr_file = split(",", $opt_sr_file);

# recycle
if(@opt_sr_file == 1 and $opt_passes > 1){
	@opt_sr_file = ($opt_sr_file[0]) x $opt_passes;
}
if(@opt_sr_file != $opt_passes){
	pod2usage(
		'-msg' => "number of '--sr' files (". scalar @opt_sr_file .") differs from number of --passes ($opt_passes)",
		'-exitval' => 1
	);
}

# lr file
if($opt_lr_file){
	$v->exit($opt_lr_file.": ".$!) unless -e $opt_lr_file;
	foreach my $orf (@opt_sr_file){
		$v->exit($orf.": ".$!) unless -e $orf;
	}
}elsif($opt_sam_file){
	$v->exit($opt_sam_file.": ".$!) unless -e $opt_sam_file;
}
	


# get prefix from input files, if none specified
unless($opt_prefix){
	if($opt_lr_file){
		my ($pb_name, $pb_path, $pb_suffix) = fileparse($opt_lr_file, qw(.fasta .fa .fastq .fq));
		my ($sr_name, $sr_path, $sr_suffix) = fileparse($opt_sr_file, qw(.fastq .fq));
		$opt_prefix = $sr_name.'#'.$pb_name;
	}else{
		my ($prefix, $path, $suffix) = fileparse($opt_sam_file, qw(.sam));
		$opt_prefix = $prefix;
	}	
}

my $opt_sam_tmp = $opt_prefix.".tmp.sam";
my $opt_log = $opt_prefix.".log";
my $opt_fa_out = $opt_prefix.".fa";
my $opt_fq_out = $opt_prefix.".fq";

# DEPRECATED
#my @opt_full_threshold = split(",", $opt_full_threshold);

# create tmp folders
my @tmp_dirs = map{$opt_prefix."_p".$_}(0..$opt_passes);
make_path(@tmp_dirs);

# coverage settings
# TODO: coverage from params
# Coverage =~ Binsize/BinMaxCoverage * readlength/2
# 100 =~ 20/10 * 100/2
#$Sam::Seq::BinMaxCoverage = int($opt_cov/10);

Sam::Seq->MaxCoverage($opt_cov);
Sam::Seq->BinSize(20);
Sam::Seq->Trim($cfg{'sr-trim'});
Sam::Seq->InDelTabooLength($cfg{'sr-indel-taboo-length'});


##------------------------------------------------------------------------##

=head1 MAIN

=cut



# reads sam or run shrimp
if($opt_sam_file){
	my $lr_chunk_offsets = prepare_lr();
	read_sam();
	@PB_IDS = sort keys %PB;
	my $sam_chunk_offsets = create_sorted_sam();
	correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
}else{
	# read and prepare lr
	$PASS = 0;
	my $lr_chunk_offsets = prepare_lr();
	
	# first pass
	$PASS++;
	# run shrimp
	my $shrimp = run_shrimp();
	# check if something went wrong with shrimp
	$shrimp->status() eq 'canceled' &&	$v->exit("Shrimp terminated abnormally\n".$shrimp->log_string);
	
	@PB_IDS = sort keys %PB;
	# create filtered sam
	my $sam_chunk_offsets = create_sorted_sam();
	# correct reads with filtered sam

	$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
	%PB = ();
	
	# second/final pass
	$PASS++;

	$shrimp = run_shrimp();
	# check if something went wrong with shrimp
	$shrimp->status() eq 'canceled' &&	$v->exit("Shrimp terminated abnormally\n".$shrimp->log_shrimp);

	$sam_chunk_offsets = create_sorted_sam();

	correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);

	# create final output
	copy(pass_file_name(".fa"), $opt_fa_out);
	copy(pass_file_name(".fq"), $opt_fq_out);

}



# remove tmp
$v->verbose("Cleaning up temporary files and memory");

# unlink $opt_sam_tmp;

%PB = ();

# lets see if we came this far
$no_error++;

# put in END to wait for memory to be cleaned
END{
	remove_tree(@tmp_dirs) unless $opt_keep;
	if ($no_error){
		Verbose->new()->verbose("Done");
	} 
}




##------------------------------------------------------------------------##

=head1 METHODS

=cut



=head2 read_sam



=cut

sub read_sam{
		# init input stream parser
	my $rsp = Sam::Parser->new(
		file => $opt_sam_file
	);
	
	# init input stream parser progess bar	
	my $pg_rsp = Verbose::ProgressBar->new(
		size => $rsp->fh
	);
	
	# init temporary sam writer
	my $tsp; 
#	$tsp = Sam::Parser->new(
#		file => pass_file_name("_tmp.sam"),
#		overwrite => 1,
#	);
	
	# read sam header
	
	while(my %h = $rsp->next_header_line('SQ|PG')){
		$pg_rsp->update();
		# @PG
		if($h{tag} eq '@PG'){
			$PG_line = $h{raw};
			next;
		}
		$PB{$h{'SN'}} = Sam::Seq->new(
			id => $h{SN}, 
			len => $h{LN},
			sam => $tsp,	# indexed sam file, containing aln data
		);
	}
	
	
	# read sam file
	my $rsp_c = 0;
	if($opt_ram_sam){
		while(my $aln = $rsp->next_aln()){
			# try to add aln, if sufficient score, add to temporary sam file
			$rsp_c++ if($PB{$aln->rname}->add_aln_by_score($aln));
			$pg_rsp->update() unless $rsp_c%10000;
		}
	}else{
		while(my $aln = $rsp->next_aln()){
			# try to add aln, if sufficient score, add to temporary sam file
			if($PB{$aln->rname}->add_aln_by_score($aln)){
				$rsp_c++;
				$tsp->append_aln($aln);
			};
			$pg_rsp->update() unless $rsp_c%10000;
		}
	}
	$pg_rsp->finish();
	
}


=head2 run_shrimp

Run and process shrimp first pass

=cut

sub run_shrimp{
	
	$v->verbose("Run and process Shrimp pass $PASS output");
	
	# init input stream parser progess bar	
	my $pg_rsp = Verbose::ProgressBar->new(size => $opt_sr_count);
	my $pg_step = int(($opt_sr_count/100)+0.5);
	
	# shrimp
	my $shrimp;
	#-r 25% -w 120% -s w10
	
	# first (second last) pass
	if($PASS == $opt_passes - 1){
		# init shrimp handler
		$shrimp = Shrimp->new(
			%{$cfg{"shrimp:$PASS"}}, # basic shrimp params from cfg
			verbose => 1,
			'log' => pass_file_name("_shrimp.log"),
			$opt_raw_sam ? ('out' => pass_file_name("_raw.sam")) : (),
			'-ref' => pass_file_name('.fa', pass => $PASS-1),
			'-1' => $opt_sr_file[$PASS-1],
			'--threads' => $opt_threads,
			'--qv-offset' => $opt_sr_qv_offset,
			'--progress' => $pg_step,
		);
	# final pass
	}elsif($PASS == $opt_passes){
		# init shrimp handler
		$shrimp = Shrimp->new(
			%{$cfg{"shrimp:$PASS"}}, # basic shrimp params from cfg
			verbose => 1,
			'log' => pass_file_name("_shrimp.log"),
			$opt_raw_sam ? ('out' => pass_file_name("_raw.sam")) : (),
			'-ref' => pass_file_name(".fm", pass => $PASS-1),
			'-1' => $opt_sr_file[$PASS-1],
			'--threads' => $opt_threads,
			'--qv-offset' => $opt_sr_qv_offset,
			'--progress' => $pg_step,
		);
	}else{
		$v->exit("No shrimp config for $PASS");
	}

	$vb->hline();
	$vb->verbose($shrimp->command());
	$vb->hline();
	
	# run shrimp
	$shrimp->run;

	# init input stream parser
	my $rsp = Sam::Parser->new(
		fh => $shrimp->oh
	# init temporary sam writer
	);
	
	my $tsp = $opt_ram_sam ? undef : Sam::Parser->new(
		file => pass_file_name("_tmp.sam"),
		mode => '+>',
	);
	
	$v->verbose("Indexing Long reads");
	# read SAM header
	while(my %h = $rsp->next_header_line('SQ|PG')){
		# @PG
		if($h{tag} eq '@PG'){
			$PG_line = $h{raw};
			next;
		}
		$PB{$h{'SN'}} = Sam::Seq->new(
			id => $h{SN}, 
			len => $h{LN},
			sam => $tsp,	# indexed sam file, containing aln data
		);
	}

	$PG_line = '@PG ID:unknown' unless $PG_line;

	$v->verbose("Mapping short reads");

	# read SAM alignmetn section
	my $rsp_c = 0;
	my $add_c = 0;
	my $cur_c = 0;
	# shrimp log
	my $slh = $shrimp->logh;
	
	if($opt_ram_sam){
		while(my $aln = $rsp->next_aln()){
			# try to add aln
			$add_c++ if($PB{$aln->rname}->add_aln_by_score($aln));
			# monitor shrimp progress
			unless($rsp_c% $pg_step){
				seek($slh, -50, 2); # get, ..
				read($slh, my $tail, 50); # .. read, .. 
				# .. and parse last 50 chars of shrimp log for number of processed reads
				$pg_rsp->update($tail =~ /(\d+)\s+\S+\s+\S+\s*$/); 
			}
			$rsp_c++;
		}
	}else{ # create tmp sam
		while(my $aln = $rsp->next_aln()){
			# try to add aln, if sufficient score, add to temporary sam file
			if($PB{$aln->rname}->add_aln_by_score($aln)){
				$add_c++; 
				$tsp->append_aln($aln);
			};
			# monitor shrimp progress
			unless($rsp_c% $pg_step){
				seek($slh, -50, 2); # get, ..
				read($slh, my $tail, 50); # .. read, .. 
				# .. and parse last 50 chars of shrimp log for number of processed reads
				$pg_rsp->update($tail =~ /(\d+)\s+\S+\s+\S+\s*$/); 
			}
			$rsp_c++;
		}
	}
	
	$pg_rsp->finish($opt_sr_count);
	
	# finish shrimp run
	return $shrimp->finish;
	
	$vb->hline();
}



=head2 create_sorted_sam

=cut

sub create_sorted_sam{
	my $opt_sam_out = pass_file_name(".sam");
	
	$v->verbose("Creating filtered sam ".$opt_sam_out);
	$v->verbose("Writing ".keys (%PB)." pacbio read sam blocks");
	
	open(OUT, '>',$opt_sam_out) or $v->exit($!);
	
	# header section
	printf OUT ("\@HD\tVN:%s\tSO:%s\n", "unknown", "unknown");
	foreach my $pb_id (@PB_IDS){
		printf OUT ("\@SQ\tSN:%s\tLN:%s\n", $pb_id, $PB{$pb_id}->len);
	}
	
	# header @PG
	print OUT $PG_line;
	
	# init input stream parser progess bar	
	my $pgb = Verbose::ProgressBar->new(size => scalar @PB_IDS);
	
	my @chunk_idxs;
	# alignment section
	my $pb_c = 0;
	foreach my $pb_id (@PB_IDS){
		push @chunk_idxs, tell(OUT) unless $pb_c % $opt_chunk_size;
		foreach my $aln($PB{$pb_id}->alns($opt_sort_sam_by_coords)){
			print OUT $aln->raw;
		}
		$pgb->update($pb_c);
		$pb_c++;
	}
	$pgb->finish($pb_c);
	
	close OUT;
	
	return \@chunk_idxs;
}




=head2 prepare_lr

Read the pacbio long read file and create a new, indexed long read file,
 ordered the same way as the sorted sam files.

=cut

sub prepare_lr{
	my ($lrpr, $lrpw);
	$lrpr = Fasta::Parser->new(file => $opt_lr_file)->check_format();
	$lrpr = Fastq::Parser->new(file => $opt_lr_file)->check_format() unless $lrpr;
	$lrpr || $v->exit("Unknown format in '--long-read' file: ".$opt_lr_file);

	$lrpw = Fasta::Parser->new( 
		file => pass_file_name(".fa", pass => $PASS), 
		mode => '+>'
	);
	
	# read fasta/fastq, write and sort by id
	my %lr;
	
	if(ref $lrpr eq 'Fasta::Parser'){
		while(my $lr = $lrpr->next_seq){
			# convert FASTQ to FASTA
			$lr->seq(lc($lr->seq()));
			$lr{$lr->id} = $lr;
		}
	}else{
		while(my $lr = $lrpr->next_seq){
			# convert FASTQ to FASTA
			$lr{$lr->id} = Fasta::Seq->new(
				id => $lr->id,
				desc => $lr->desc,
				seq => lc($lr->seq),
			);
		}
	}
	
	
	# write sorted/indexed fq/fa lr file for pbc
	my @lr_idxs;
	my $lr_c = 0;
	foreach(sort keys %lr){
		my $pos = $lrpw->append_seq($lr{$_});
		push @lr_idxs, $pos unless $lr_c % $opt_chunk_size;
		$lr_c++;
	}
	return \@lr_idxs;
}



=head2 correct_sr_mt

=cut

sub correct_sr_mt{
	my ($sam_chunk_offsets, $lr_chunk_offsets) = @_;
	
	$v->verbose("Correcting Sequences (".@$sam_chunk_offsets." batches)");
	
	# pbc_correct.pl 
	my %pbc_default = (
		'--sam' 		=> pass_file_name(".sam"),
		'--sam-offset' 	=> undef,
		'--ref' 		=> undef,
		'--ref-offset'	=> undef,
		'--max-reads'	=> $opt_chunk_size,
		'--prefix'		=> undef,
		'--coverage'	=> $opt_cov,
		'--hcr-mask-length' => $cfg{'hcr-mask-length'},
		'--hcr-sticky-length' => $cfg{'hcr-sticky-length'},
	);
	
	my @pbc_keys = sort keys %pbc_default;
	
	my $pbc_cmds = '';
	
	# generate xargs statements foreach chunk
	for(my $ci=0; $ci<@$sam_chunk_offsets; $ci++){
		my %pbc_config = (
			%pbc_default,
			'--ref' 		=> $PASS == 1
							 	 ? pass_file_name(".f[aq]", pass => $PASS-1)
							 	 : pass_file_name(".fq", pass => $PASS-1),
			'--sam-offset' 	=> $sam_chunk_offsets->[$ci],
			'--ref-offset'	=> $lr_chunk_offsets->[$ci],
			'--prefix'		=> pass_file_name(sprintf ".%010d", $ci),
		);
		
		# params
		my @pbc_cmd;
		foreach my $k (@pbc_keys){
			my $v = $pbc_config{$k};
			# flag only is undef or '', NOT '0' !!!
			push @pbc_cmd, (defined($v) && $v ne '') ? ($k, $v) : $k;
		}
		$pbc_cmds .= join(" ", @pbc_cmd)."\n";
	}
	
	# write cmd file
	
	my $cfg_file = pass_file_name(".cfg");
	open(CFG, '>', $cfg_file) or $v->exit($!);
	print CFG $pbc_cmds;
	close CFG;
	
	# xarg cmds, capture stderr;
	my $xgr;
	open($xgr, "(xargs --arg-file $cfg_file --max-procs $opt_threads -L 1 --verbose perl $RealBin/sam2cns) 2>&1 |")
		or $v->exit($!);
	
	$vb->hline();
	# 
	my $bc;
	my $bs = "Batch %d/".@$sam_chunk_offsets;
	while(<$xgr>){
		chomp();
		if ($_ =~ /^perl /){
			$v->verbose(sprintf($bs, ++$bc));
			$vb->verbose($_);
			$vb->hline() 
		}else{
			$vb->verbose($_);
		}
		
		if(/xargs:.*255/){
			$v->exit("sam2cns returned with error");
		}
	}
	
	
	$v->verbose("Merging corrected output");
	my $fq_file = pass_file_name(".fq");
	my $fq_glob = pass_file_name(".[0-9]*.fq");
	my $fa_file = pass_file_name(".fa");
	my $fa_glob = pass_file_name(".[0-9]*.fa");
	my $fm_file = pass_file_name(".fm");
	my $fm_glob = pass_file_name(".[0-9]*.fm");
	
	my @fq_glob = glob $fq_glob;
	my @fa_glob = glob $fa_glob;
	my @fm_glob = glob $fm_glob;
	
	
	# create offset idx for reference
	my @ref_idxs = (0);
	my $offset = 0;
	# get fq indexes
	foreach(@fq_glob){
		$offset+= -s $_;
		push @ref_idxs, $offset;   
	}
	
	# remove last on, its just the eof
	pop(@ref_idxs);
	
	qx(cat $fq_glob > $fq_file);
	qx(cat $fa_glob > $fa_file);
	qx(cat $fm_glob > $fm_file);
	
	unlink @fq_glob unless $opt_keep > 1;
	unlink @fa_glob unless $opt_keep > 1;
	unlink @fm_glob unless $opt_keep > 1;
	
	return \@ref_idxs;
}


=head2 file_name

Create a file name depending on current $PASS and $opt_prefix

  $PASS = 1;
  $opt_prefix = "/foo";
  pass_file_name(".suf");
    # "/foo_p1.suf"
  pass_file_name(".suf", prefix => "/foo/bar", pass => 2);
    # "/foo/bar_p2.suf"

=cut


sub pass_file_name{
	my $p = {
		prefix => $opt_prefix,
		pass => $PASS,
		suffix => (@_%2 ? shift : ''),
		@_
	};
	
	return sprintf('%1$s_p%2$d/%1$s_p%2$d%3$s', $p->{prefix}, $p->{pass}, $p->{suffix});
}


=head2 create_custom_cfg

=cut

sub copy_custom_cfg{
	my ($cfg_core_file, $cfg_custom_file) = @_;	
	open(COR, $cfg_core_file) or $v->exit($!);
	open(CUS,'>',$cfg_custom_file) or $v->exit("Couldn't create config file: $cfg_custom_file");
	
	while(<COR>){
		if(/^#/){
			next unless /^##/; 
			print CUS $_;
		}else{
			if(/^\s*$/){
				print CUS $_;
			}else{
				print CUS '#',$_; 
			}
		}
	}
	
	close COR;
	close CUS;		
}

=head2 coverage_tables

=cut

sub coverage_tables{
	my $opt_fq_out = pass_file_name("fq");
	
	# progess bar	
	my $pgp = Verbose::ProgressBar->new(
		size => scalar keys %PB 
	);

	$v->verbose("Calculating exact coverage by score tables ".$opt_fq_out);

	my $i=1;
	while(my ($pb_id, $pb) = each %PB){
		my @COV;
		my $ofh;
		if($opt_fq_out eq '-'){
			$ofh = \*STDOUT;
		}else{
			open($ofh, '>', pass_file_name('_'.$i.'.tsv')) or $v->exit($!);
		}
		foreach my $score_co(1..1000){
			$pb->is(sub{ 
				my $score = $_[0]->opt('AS');
				return $score == $score_co
			});
			# add to previous cov
			push @COV, [$pb->coverage];
		}
		print $ofh join("\t", @$_)."\n" for @COV;
		close $ofh if $opt_fq_out ne '-';
		
		$pgp->update($i++);
	}
	$pgp->finish($i);


	#printf $ofh ("\@%s\n%s\n+\n%s\n", $pb->consensus);
	#my @cov = $pb->coverage;
	#my @cov1 = grep{defined($_) && $_>0}@cov;
	#
	#print "#"x30, "\n";
	#printf "%-8s %6.1f\n", 'Score:', $score_co; 
	#next unless @cov;
	##printf join(" ", @cov), "\n";
	#printf "%-8s %6.1f%%\n", 'Covered:', (@cov1/$pb->len)*100,
	#printf "%-8s %6.1f\n", 'Mean:', sum(@cov)/@cov;
	#printf "%-8s %6.1f\n", 'Max:', max(@cov);
	#printf "%-8s %6.1f\n", 'Cols:', scalar @cov;

}



##------------------------------------------------------------------------##

=head1 AUTHORS

=over

=item * Thomas Hackl, thomas.hackl@uni-wuerzburg.de

=back
