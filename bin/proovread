#!/usr/bin/env perl

use warnings;
use strict;

use Getopt::Long;
use Pod::Usage;
use List::Util qw(sum max);

use FindBin qw($RealBin);
use lib "$RealBin/../lib/";

use File::Basename;
use File::Path qw(make_path remove_tree);
use File::Copy;

use Verbose;
use Verbose::ProgressBar;

use Fastq::Parser 0.09;
use Fastq::Seq 0.13;

use Fasta::Parser 0.08;
use Fasta::Seq 0.07;

use Sam::Parser 0.11;
use Sam::Alignment 0.0 ':flags';
use Sam::Seq 0.10;

use Shrimp 0.08;
use Bowtie2 0.01;

use threads;
use Thread::Queue;
use Time::HiRes qw(usleep);

use Data::Dumper;
$Data::Dumper::Sortkeys = 1;

our $VERSION = '2.01';

my $RealLib = "$RealBin/../lib/";
my $RealPerl = "perl -I${RealLib} $RealBin";
=head1 NAME

proovread

=cut

=head1 DESCRIPTION

Correct single molecule sequencing reads by iterative mapping of high
 throughput sequencing reads.

=cut

=head1 CHANGELOG

=cut

=head2 1.04

=over

=item [Feature] NEW This version of proovread should also work on MacOSX systems

=item [Feature] NEW SeqChunker-perl, as a perl only implementation of
the SeqChunker code. This should work on every operating system offering perl.
This implementation is the default SeqChunker used.

=item [Feature] NEW SeqChunker.sed, for bash versions older than 4.0.
 Automatically choosen when bash is older than V. 4.0  

=item [Change] Changed standart mapping options for pre-mapping steps.

=item [Upgrade] Upgraded Shrimp module version to 0.08

=item [Requirements] NEW Required perl modules: Log::Log4perl, Log::Log4perl::Appender::Screen

=item [Requirements] NEW Required software: blastn for detection of chimera

=back

=cut

=head2 1.03

=over

=item [Change] "weak-read" can be controlled in cfg via 'mask-weak-reads'. 
 Handling has been adjusted.

=item [Feature] new SeqChunker, sampling is now controlled by sr-sampling in
 cfg. $opt_cov is adjusted if data is sampled.

=back

=cut

=head2 1.02

=over

=item [Feature] cfg() to retrieve task specific entries from config. 

=item [Change] Removed --ram-sam feature.

=item [Change] Do not --mask-weak-reads in pre-1.

=back

=cut

=head2 1.01

=over

=item [Feature/Change] dynamic --lcr-min-ratio w/r/t short read length 
 replaces fixed --min-lcr-length.

=item [BugFix] --min-lcr-length not correctly respected in sam2cns.

=item [Feature] Less biased on the fly sampling of short reads by feeding 
 SeqChunker output to shrimp STDIN.

=back

=cut


=head2 1.00

=over

=item [Feature] sam2cns: C<< lcr-end-ratio >> to control end mask/unmask behaviour.

=item [BugFix] ProgressBar in "pre" mode now has correct length.

=item [Change] Removed C<< --finish-aligned-only >>.

=item [Feature] Improved masking in sam2cns.

=item [Feature] Ignore long reads shorter than 200% of mean short read length

=item [Feature] Bowtie2.

=item [Feature] C<< --sr-qv-offset >> as command line option.

=item [Feature] C<< --sample >> runs the F.antasticus sample set.

=back

=cut

=head2 0.91

=over

=item [BugFix] --substr chimera out of seq boundaries due to error in sam2cns.

=item [Change] The primary format of prepared reads is now only FASTA if 
 FASTA was provided, but FASTQ if FASTQ is provided to allow for HCR 
 restoration.

=item [Change] Rearranged order of preparations to allow folder creation
 prior to parameter log.

=item [BugFix] 'external-sam' with reference did not set --ref-offset for 
 sam2cns.

=item [Feature] config settings and commandline parameter are dumped directly
 to a file instead of being printed to log.

=item [BugFix] chim_filter() did not create valid input for param_join() and
 hence failed to create valid parameter for ChimeraToSeqFilter.

=item [Feature] 'external-sam' mode accepts reference file including HCR 
 information.

=item [Feature] SeqFilter reads filtered chimera annotations to --substr
 to trim chimeric reads.

=item [Feature] ChimeraToSeqFilter.pl creates filtered chimera annotations.

=item [Change] Only cleanup if finished w/o errors.

=item [BugFix] Terminating shrimp early requires monitoring the short read
 count from the shrimp log and comparing it to the cutoff. Uninitialized 
 count causes errors in this comparison.

=back

=head2 0.90

=over

=item [Change] MaxCoverage is adjusted each stage to the to account for
 --sr-pre-fraction settings.

=item [Change] Made shrimp-pre the default mode. Finish-with-aligned only
 is by default deactivated in this mode regardless of coverage.

=item [Feature] The fractions of short reads mapped in pre stages are 
 controlled individually for each stage by --sr-pre-praction in .cfg.

=item [Feature] shrimp-pre. Pre correct long reads with fraction of short 
 reads to increase overall speed.

=item [Feature] Usage of latest Fastq::Parser module allows direct reading
 of gzipped short read files.

=item [Feature] Specify --overwrite to replace already exiting output
 directories.

=back

=head2 0.85

=item [Feature] Chimera detection returns score for threshold.

=item [Feature] SeqFilter does --substr on chimera coords file.

=head2 0.84

=over

=item [Change] Allow larger inserts in finish iteration using sam2cns
 --max-ins-length. Long inserts in the primal iterations are likely to be
 mapping artefact. In the finishing step, they are more likely to be missed
 in the first placed as the could not be distinguished from mapping artefacts.

=item [BugFix] read_sam() exits if no Reference Sequence Entry '@SQ'
 for a given sequence could be found in the header. 

=item [Change] SeqFilter replaces FastqFilter.pl for final filtering.

=item [BugFix] Short reads stats are not computed in case of 'external-sam'. 

=back

=head2 0.83

=over

=item [BugFix] Only processed first of multiple short read files in mapping.
 Fixed this here, requires Shrimp-0.06, to store genome projections in between
 short read runs.

=item [Feature] Chimera detection.

=back

=head2 0.82

=over

=item [BugFix] C<$pg_step> is used in modulo, cannot be 0.

=item [Change] sam2cns-0.04 C<--lcr-min-length> calculated from mean short
 read length

=item [Feature] verbose print cfg and commandline parameter

=item [BugFix] Incorrect parameter for sam2cns, fix by new method 
 C<param_join()>  

=item [BugFix] --ignore-sr-length did not work and ccs expected 
 length was increased to 1000

=item [Feature] external-sam mode

=item [Feature] FastqFilter.pl default settings from config.

=item [Feature] FastqFilter.pl is automatically run on results to produce
 a trimmed output.
 
=back


=head2 0.81

=over


=item [Change] Cleaned up verbose messages. 

=item [Feature] Final finishing task using aligned and dumped short reads 
 from previous runs to further increase accuracy.

=item [Feature] Support of multiple short and long read files at the same time.

=back


=head2 0.80

=over

=item [Change] Prefix defaults to proovread_<TIMESTAMP>.

=item [Feature] Scripts stops if output directory cannot be created/
 is not empty.

=item [Change] Chunk files have natural consecutive numbering scheme
 and are sorted using C<byfile()> to keep there order consistent. This
 makes the chunk filename robust for any number of chunks.

=item [Feature] C<byfile()> sorting function for "natural" file sorting

=item [Refactoring] Changed PASS based workflow to TASK based 
 workflow, where tasks can be modularily put together to adjust for
 different scenarios. TASK order can easily configured via the 
 config file.

=item [Feature] Config provides 'modes', which essentially are 
 templates running specific TASKs for different scenarios. 

=back

=head2 0.72

=over

=item [Feature] Added C<sr-trim> and C<sr-indel-taboo> to advanced
 config options

=item [Change] Uses Sam::Seq 0.08, which provides InDelTabooLength based 
 short read trimming to reduce errors especially in edge regions

=item [Change] Binary path is now determined by $FindBin::Realbin instead of
 $FindBin::Bin. Robust against linking the binary.

=item [Feature] Read short reads FASTA input

=item [Change] remove_tree moved to END{}, to delete folders also in case of 
 an error

=item [BugFix] Bad rounding, $pg_step could become 0, does not work in modulus

=back

=head2 0.71

=over

=item [Feature] Test config file for existence before loading.

=item [Feature] proovread now reads all parameter from a default core config
 (proovread.cfg). Additionally an optional, customized config file can be
 generated for user modification C<< --create-cfg >> and the modified config
 can be provided to the pipeline with C<< -c/--cfg >>. Highest controll 
 priority remains with the scripts command line parameter, yet the configs 
 manipulate the defaults and allow additional advanced settings, like shrimp
 mapping parameter, which cannot be controlled via command line. 

=back

=head2 0.70

=over

=item [Feature] Shrimp progress bar now displays to actual precentage of 
 mapped reads und computes ETA, using the --sr-count guess and on the fly
 parsing of the Shrimp progress from the Shrimp log file.

=item [Feature] "--sr-count" with auto-guess, used for eta calculations.

=item [Feature] "--sr-length" with auto-guess.

=item [Feature] "--sr-qv-offset" with auto-guess.

=item [Renaming] "--qv-offset" to "--sr-qv-offset" 

=item [Renaming] "--reads" to "--short-reads" and "--ref" to "--long-reads"

=item [Change] C<--qv-offset> is now required without default. 

=item [Change] Rearranged parameter specs, removed parameter currently not working/under
 development.

=item [Renaming] <reads> variables to <sr>, <ref> to <lr>.

=item [Change] Default C<--full-threshold> to 55%,35%.

=item [Change] Reduced gap extension costs for shrimp by one to prevent 
 misalignments of Triplet/... insertions in variants and to account
 for slight bias towards homopolymer errors.

=back

=head2 0.60

=over

=item [Bugfix] --reads did not recycle value, if only one set was given and 
 multiple passes are run.

=item [Refactoring] Versionized.

=back

=cut

=head1 TODO

=over

=item read-sam on with .fq reference, hcrs fail on .fa

=item test multi-file support for non-standard modes

=item masking stats between runs -> SeqFilter

=back

=cut

##------------------------------------------------------------------------##

my $no_fatal;

# verbose
my $V = Verbose->new(
	format => "  {MESSAGE}\n",
	line_width => 80,
);

# verbose
my $VS = Verbose->new(
	format => "[{TIME_FULL}] {MESSAGE}\n",
	line_width => 80,
);

# verbose bash style
my $VB = Verbose->new(
	line_delim => "\\\n",
	line_width => 80,
	format => "{MESSAGE}\n",
);




=head1 OPTIONS

=cut

=over

=cut

# load core defaults
$VS->verbose("Reading core config");
my $cfg_core_file = "$RealBin/../proovread.cfg"; 
my %cfg = do $cfg_core_file;
$V->exit("An error ocuured while processing the config file: $@") if $@; # capture do errors on cfg

=item [--create-cfg=<CFGFILENAME>] [<CWD>/proovread_cfg.pm]

Create a custom config file. Unless you provide a PATHNAME, defaults to 
 CWD/proovread.cfg. Does not run the pipeline. The custom config file 
 can be modified/renamed and supplied to the pipeline using -c/--cfg. The
 config file is optional, supercedes default parameters, but has lower 
 priority than command line options. The config fall also allows control
 of advanced options, not available via command line. For details, create
 a config file and have a look at its header section.

=item [-c, --cfg]

Custom config file.

=cut

# load user defaults and overwrite core
my $cfg;
for(my $i=0; $i<@ARGV; $i++){
	if($ARGV[$i] =~ /--create-cfg$/){
		my $cfg_custom_file = $i < $#ARGV ? $ARGV[$i+1] : basename($cfg_core_file);
		$VS->verbose("Creating custom config file `$cfg_custom_file`");
		copy_custom_cfg($cfg_core_file, $cfg_custom_file);
		exit(0);
	}
	if($ARGV[$i] =~ /-c$|--cfg$/){
		$cfg = $ARGV[$i+1];
		last;
	}
}

if($cfg){
	unless(-e $cfg){
		$VS->exit("Cannot find config file `$cfg`");
	}
	$VS->verbose("Reading custom config `$cfg`");
	%cfg = (%cfg, do "$cfg"); 
	$V->exit("An error ocuured while processing the config file: $@") if $@; # capture do errors on cfg
}

$VS->verbose("Reading command line options");

# load cmd options and overwrite defaults
my %opt;

$opt{'c|cfg=s'} = \$cfg;

=item -l, --long-reads=<PATHNAME>

Pacbio reads file to correct. FASTA or FASTQ format. To correct
 mulitple files at once, provide parameter mulitple times.
 
  -l cell1 -l cell2 ... # correct 2 cells at once

=cut

$opt{'l|long-reads=s@'} = \(my $opt_lr_file = cfg('long-reads'));

=item -s, --short-reads=<PATHNAME>

High confidence short reads file used for correction in FASTQ or
 FASTA format.
To correct with mulitple files at once, provide parameter mulitple
 times.

NOTE: If multiple libraries are provided, they need to be of the 
 same format (FASTA or FASTQ) and quality offset (33,64...)
 respectively.

  -s lib1 -s lib2 # use reads from to libraries for correction

=cut



$opt{'s|short-reads=s@'} = \(my $opt_sr_file = cfg('short-reads'));

=item -u, --unitigs=<PATHNAME>

High confidence unitigs to use for correction. Can be specified
multiple times.

=cut

$opt{'u|unitigs=s@'} = \(my $opt_utg_file = cfg('unitigs'));

=item [-p, --prefix=<STRING>]

Prefix to output files. Defaults to 'proovread'.

=cut

$opt{'p|prefix=s'} = \(my $opt_prefix = cfg('prefix'));

=item [--coverage=<INT>] [50]

Coverage cutoff for highest scoring mappings at each location.

=cut

$opt{'coverage=s'} = \(my $opt_cov = cfg('coverage'));

=item [-t, --threads] [8]

Number of threads to use for mapping. Defaults to 8 (or maximum available 
 number of processors, if kess than 8 availabe).

=cut

$opt{'t|threads=i'} = \(my $opt_threads = cfg('threads'));

=item [-m, --mode] [auto]

Running mode of the pipeline, accepted values are 
 'pacbio-iterative', 'pacbio-ccs', 'external-sam'. By default, the
 most appropriate mode is choosen based on the provided input data.
 See manual for further information. 

=cut

$opt{'m|mode=s'} = \(my $opt_mode);

=item [--sam] [8]

External SAM file to compute corrected consensus sequences from. 
 Provide as input instead of --long-reads/--short-reads. Automatically
 sets --mode to 'external-sam'.
 
=cut

$opt{'sam=s'} = \(my $opt_sam_file = cfg('sam'));

=item [--lr-qv-offset=<INT>]

Required if you use --sam and --long together and the phred offset cannot be
 determined automatically from --long read file.
 
=cut

$opt{'lr-qv-offset=i'} = \(my $opt_lr_qv_offset = cfg('lr-qv-offset'));

=item [--sr-qv-offset=<INT>]

Required if phred offset cannot be determined automatically from --short read file.
 
=cut

$opt{'sr-qv-offset=i'} = \(my $opt_sr_qv_offset = cfg('sr-qv-offset'));


=item [--sort-sam-by-coordinates] [OFF]

Sort the filtered SAM files by coordinates in addition to the 
 sorting of references. This has no effect on the pipeline, just 
 a convenience if you need the files for something else.

=cut

$opt{'sort-sam-by-coordinates'} = \(my $opt_sort_sam_by_coords = cfg('sort-sam-by-coordinates'));

=item [--keep-temporary-files] [OFF]

Specify once, to keep temporary file of each task, twice to also keep the
 individual temporary file of each thread.

=cut

$opt{'keep-temporary-files+'} = \(my $opt_keep = cfg('keep-temporary-files'));

=item [--ignore-sr-length]

Since the pipeline is designed to use short reads for correction, it stops
 in case an average short read length above 700bp has been estimated. Set 
 C<--ignore-sr-length> to omit this test.

=cut

$opt{'ignore-sr-length'} = \(my $opt_ignore_sr_length = cfg('ignore-sr-length'));

=item [--overwrite]

Overwrite output folder if it already exists.

=cut

$opt{'overwrite'} = \(my $opt_overwrite = cfg('overwrite'));

=item [--sample]

Run the sample data set.

=cut

$opt{'sample:s'} = \(my $opt_sample);

=item [-h, --help]

Show this help.

=cut

$opt{'h|help'} = \(my $opt_help);

=back

=cut

## DEPRECATED
##$opt{'ram-sam'} = \(my $opt_ram_sam = cfg('ram-sam'));

##------------------------------------------------------------------------##


# parse options, test files
GetOptions(%opt) or pod2usage(1);
$opt_help && pod2usage(1);

if(defined $opt_sample){
    if($opt_sample =~ /^ec/i){
        $opt_lr_file = ["$RealBin/../sample/Ec-pb.fq"];
        $opt_sr_file = ["$RealBin/../sample/Ec-il-sim50X_1.fq"];
        $opt_sr_qv_offset = 64;
        $opt_prefix = 'pr-Ec' unless $opt_prefix;

    }else{
        $opt_lr_file = ["$RealBin/../sample/F.antasticus_long_error.fq"]; #
	$opt_sr_file = ["$RealBin/../sample/F.antasticus_short.fq"]; #
	$opt_sr_qv_offset = 33;
        $opt_prefix = 'pr-Fa' unless $opt_prefix;
    }
} 

$opt_sam_file || (@$opt_lr_file && @$opt_sr_file) || (@$opt_lr_file && @$opt_utg_file) || pod2usage("Either --long-reads and --short-reads/--unitigs or --sam required");
$opt_sam_file && ! -f $opt_sam_file && pod2usage("Cannot find sam file `$opt_sam_file`");


##------------------------------------------------------------------------##

=head1 PRE

=cut

=head2 create folder structure

=cut

$opt_prefix = 'proovread' unless $opt_prefix;
$VS->exit("Bad chars in prefix: $opt_prefix") if $opt_prefix =~ '^-';

# DEPRECATED
#unless ($opt_prefix){
#	my @time = (localtime(time))[reverse(0..5)];
#	$time[0]+=1900;
#	$time[1]++;
#	$opt_prefix = 'pr_'.sprintf("%4d-%02d-%02d_%02d-%02d-%02d", @time)
#}

# create tmp folders
if(-e $opt_prefix){
	if(-d $opt_prefix){
		if($opt_overwrite){
			remove_tree($opt_prefix);
		}else{
			$VS->exit("Output directory already exists and is not empty")
			unless is_empty_dir($opt_prefix);
		}
	}else{
		$VS->exit("Output directory already exists, yet is no directory")
	} 
} 
make_path($opt_prefix);



##------------------------------------------------------------------------##

=head2 log parameter

=cut

# 'cause I'm lazy


my $opt_param_log = task_file_name(task => '', suffix => ".parameter.log");
open(PARAM, '>', $opt_param_log) or $V->exit("$!: `$opt_param_log`");

$VS->verbose("Logging parameter to `$opt_param_log`");

my $cfg_string = Dumper(\%cfg);
$cfg_string =~ s/^.*\n//;
$cfg_string =~ s/\n.*$//;
print PARAM "Custom config parameter\n",$cfg_string;

my $cmd_string = Dumper(\%opt);
$cmd_string =~ s/^.*\n//;
$cmd_string =~ s/\n.*$//; 
print PARAM "Command line parameter\n",$cmd_string;

close PARAM;

##------------------------------------------------------------------------##

my @sr_length;
my @sr_length_dev;
my @sr_count;
my $sr_count_total;
my $sr_qv_offset_total;
my @sr_matched;
my @sr_bps;

my $min_sr_length;
my $max_sr_dev;

if(@$opt_sr_file){
	$VS->verbose("Checking short read files");
	
	# short read files
	foreach(@$opt_sr_file){
		-e $_ || $VS->exit("Cannot find short read file `$_`");
	
		$V->verbose("\n".basename($_));
		
		# test if short reads are FASTQ/FASTA
		my $fp;
		my $sr_length;
		my $sr_length_dev = '0';
		my $sr_qv_offset;
		my $sr_count;
		
		# FASTQ
		if($fp = Fastq::Parser->new(file => $_)->check_format){ 
			# format
			$V->verbose("Detected FASTQ format");
			
			# length
			($sr_length, $sr_length_dev) = $fp->guess_seq_length;
			$V->verbose(sprintf("Estimated short read length: %d +-%d", $sr_length, $sr_length_dev ));
			if(!$opt_ignore_sr_length && $sr_length > 1000){
				$V->exit(
					"Estimated short reads length > 1000\n"
					."Are you sure you specified the correct data? "
					."To run the pipeline on this data, which by design is not really suited, "
					."you need to specify --ignore-sr-length"
				);
			}
			
			# offset
			unless (defined $opt_sr_qv_offset){ # manual overwrite from config
				$sr_qv_offset = $fp->guess_phred_offset; 
				$V->exit(
					"Estimating short read quality offset failed.\n"
					."See 'sr-qv-offset' in the advanced section for manual overwrite"
				) unless defined $sr_qv_offset;
				$V->verbose(sprintf("Etimated short read quality offset: %d", $sr_qv_offset));
				
				if(defined($sr_qv_offset_total)){
					$sr_qv_offset_total == $sr_qv_offset || $VB->exit('Different formats/quality offsets in short read files not allowed');
				}else{
					$sr_qv_offset_total = $sr_qv_offset;
				}
			}
			
			# count
			$sr_count = $fp->guess_seq_count();
			$V->verbose(sprintf("Estimating approximate number of short reads: %s", Verbose->Humanize($sr_count)));
		
		
		# FASTA
		}elsif($fp = Fasta::Parser->new(file=> $_)->check_format){
			# format
			$V->verbose("Detected FASTA format");
	
			# length		
			($sr_length, $sr_length_dev) = $fp->guess_seq_length;
			$V->verbose(sprintf("Estimating short read length: %d +-%d", $sr_length, $sr_length_dev));
			if(!$opt_ignore_sr_length && $sr_length > 1000){
				$V->exit(
					"Estimated short reads length > 1000\n"
					."Are you sure you specified the correct data? "
					."To run the pipeline on this data, which by design is not really suited, "
					."you need to specify --ignore-sr-length"
				);
			}
			
			if(defined($sr_qv_offset_total)){
				$sr_qv_offset_total == 0 || $VB->exit('Different formats/quality offsets in short read files not allowed');
			}else{
				$sr_qv_offset_total = 0;
			}
	
			# count
			$sr_count = $fp->guess_seq_count();
			$V->verbose(sprintf("Estimating approximate number of short reads: %s", Verbose->Humanize($sr_count)));
	
			
		}else{
			$V->exit("Short read file $_ neither FASTQ nor FASTA format");
		}
	
		# push
		push @sr_length, $sr_length;
		push @sr_length_dev, $sr_length_dev;
		push @sr_count, $sr_count;
		push @sr_bps, ($sr_count * $sr_length);
		$sr_count_total+= $sr_count;
	}
	
	$sr_qv_offset_total = $opt_sr_qv_offset unless defined $sr_qv_offset_total;
	
	if(@$opt_sr_file){
		$min_sr_length = (sort{$a<=>$b}@sr_length)[0];
		$max_sr_dev = (sort{$b<=>$a}@sr_length_dev)[0];
		$min_sr_length+=$max_sr_dev; 
	}
}


my @or_length;
my @or_length_dev;
my @or_count;
my $or_count_total;
my @or_matched;
my @or_bps;

my $min_or_length;
my $max_or_dev;

if($opt_utg_file && @$opt_utg_file){
	$VS->verbose("Checking alternative read files");
	
	# short read files
	foreach(@$opt_utg_file){
		-e $_ || $VS->exit("Cannot find alternative read file `$_`");
	
		$V->verbose("\n".basename($_));
		
		# test if short reads are FASTQ/FASTA
		my $fp;
		my $or_length;
		my $or_length_dev = '0';
		my $or_qv_offset;
		my $or_count;
		
		# FASTQ
		if($fp = Fastq::Parser->new(file => $_)->check_format){ 
			# format
			$V->verbose("Detected FASTQ format");
			
			# length
			($or_length, $or_length_dev) = $fp->guess_seq_length;
			$V->verbose(sprintf("Estimated short read length: %d +-%d", $or_length, $or_length_dev ));

                        # dont really care about length
			# dont care about offset
			
			# count
			$or_count = $fp->guess_seq_count();
			$V->verbose(sprintf("Estimating approximate number of alternative reads: %s", Verbose->Humanize($or_count)));
	
		# FASTA
		}elsif($fp = Fasta::Parser->new(file=> $_)->check_format){
			# format
			$V->verbose("Detected FASTA format");
	
			# length		
			($or_length, $or_length_dev) = $fp->guess_seq_length;
			$V->verbose(sprintf("Estimating short read length: %d +-%d", $or_length, $or_length_dev));
	
                        # dont really care about length
			# dont care about offset

			# count
			$or_count = $fp->guess_seq_count();
			$V->verbose(sprintf("Estimating approximate number of short reads: %s", Verbose->Humanize($or_count)));
	
			
		}else{
			$V->exit("Alternative read file $_ neither FASTQ nor FASTA format");
		}
	
		# push
		push @or_length, $or_length;
		push @or_length_dev, $or_length_dev;
		push @or_count, $or_count;
		push @or_bps, ($or_count * $or_length);
		$or_count_total+= $or_count;
	}
	
	if(@$opt_utg_file){
		$min_or_length = (sort{$a<=>$b}@or_length)[0];
		$max_or_dev = (sort{$b<=>$a}@or_length_dev)[0];
		$min_or_length+=$max_or_dev; 
	}
}




=head2 mode

=cut

# globals
my $PG_line = '@PG ID:unknown';

# mode
my @TASKS;
my $TC = -1;
my $TASK; # current task

if($opt_sam_file){
	$opt_mode = 'external-sam';
	@TASKS = @{$cfg{'mode-tasks'}{$opt_mode}};
}else{
	unless($opt_mode){
		if($min_sr_length > 260){
			$opt_mode = 'pacbio-ccs';
			@TASKS = @{$cfg{'mode-tasks'}{$opt_mode}};
		}else{
			$opt_mode = 'bwa-pre';
			@TASKS = @{$cfg{'mode-tasks'}{$opt_mode}};
		}
	}else{
		#print $opt_mode;
		@TASKS = @{$cfg{'mode-tasks'}{$opt_mode}};
	}
}

# DIRTY FIX: mode unitigs w/o sr reads
$min_sr_length = 200 unless $min_sr_length;

#unshift @TASKS, 0; # tasks are counted from 1, 0 just fills the array index :)

$VS->verbose('Running mode: '.$opt_mode);




=head2 create temporary folders

=cut

my @tmp_dirs = (map{$opt_prefix."/".$_}@TASKS);
make_path(@tmp_dirs);



##------------------------------------------------------------------------##

=head1 MAIN

=cut


my $LR;
my @LR_IDS;
my @LR_IDS_IGNORED;
my $lr_chunk_offsets;
my @lr_count;
my @lr_length;
my @lr_bps;
my $sr_bps_total;
my $lr_bps_total;
my $sam_chunk_offsets;
my $estimated_coverage;

foreach my $task (@TASKS){
	$TASK = $task;
	$TC++;
	if($TASK eq 'read-sam'){
		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}
$xf=1;
		Sam::Seq->MaxCoverage($opt_cov * $xf);
		Sam::Seq->BinSize(cfg('bin-size'));
                

		$LR = read_sam();
		$sam_chunk_offsets = create_sorted_sam();
		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
	}elsif($TASK eq 'read-long'){
		
		# long read files
		foreach(@$opt_lr_file){
			-e $_ || $VS->exit("Cannot find long read file `$_`");
		}
		
		$lr_chunk_offsets = read_long() if @$opt_lr_file; # 'external-sam does not require LR

	}elsif($TASK eq 'shrimp-iter-1'){

		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}
$xf=1;
		Sam::Seq->MaxCoverage($opt_cov * $xf);
		Sam::Seq->BinSize(cfg('bin-size'));
               

		run_shrimp(
			sr_files => $opt_sr_file,
			shrimp => {
				cfg($TASK), # basic shrimp params from cfg
				'verbose' => 1,
				'log' => task_file_name(suffix => "_shrimp.log"),
				'ref' => task_file_name('.masked.fa', task => $TASKS[$TC-1] ),
				#'--al' => task_file_name(suffix => "_sr.fq"),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);
	
		$sam_chunk_offsets = create_sorted_sam();
		
		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);

		$LR = undef;

	}elsif($TASK eq 'shrimp-iter-2'){

		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}
$xf=1;
		Sam::Seq->MaxCoverage($opt_cov * $xf);
		Sam::Seq->BinSize(cfg('bin-size'));


		run_shrimp(
			sr_files => $opt_sr_file,
			shrimp => {
				cfg($TASK), # basic shrimp params from cfg
				'verbose' => 1,
				'log' => task_file_name(suffix => "_shrimp.log"),
				'ref' => task_file_name(".masked.fa", task => $TASKS[$TC-1] ),
				#'--al' => task_file_name(suffix => "_sr.fq"),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);

		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
	
		$LR = undef;

############################################################################

	}elsif($TASK eq 'shrimp-pre-1'){

		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}

		Sam::Seq->MaxCoverage($opt_cov * $xf);
 		Sam::Seq->BinSize(cfg('bin-size'));
##                my $maco = $opt_cov * $xf;                           # for compare parameters with old versions
##                $VS->verbose( "--XF is $xf and $maco" );

		run_shrimp(
			sr_files => $opt_sr_file,
			sr_sampling => cfg('sr-sampling', $TASK),
#			($sr_count_total > 1_000_000
#				? (stop_after => $sr_count_total * cfg('sr-sampling', $TASK))
#				: ()
#			),
			shrimp => {
				cfg($TASK), # basic shrimp params from cfg
				'verbose' => 1,
				'log' => task_file_name(suffix => "_shrimp.log"),
				'ref' => task_file_name('.masked.fa', task => $TASKS[$TC-1] ),
				#'--al' => task_file_name(suffix => "_sr.fq"),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);
	
		$sam_chunk_offsets = create_sorted_sam();
		
		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);

		$LR = undef;

	}elsif($TASK =~ m/^shrimp-pre-[2-5]/){

		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}

		Sam::Seq->MaxCoverage($opt_cov * $xf);
		Sam::Seq->BinSize(cfg('bin-size'));
                    ##my $maco = $opt_cov * $xf;                   # for compare parameters with old versions
                    ##$VS->verbose( "--XF is $xf and $maco" ); 

		run_shrimp(
			sr_files => $opt_sr_file,
			sr_sampling => cfg('sr-sampling', $TASK),
#			($sr_count_total > 1_000_000
#				? (stop_after => $sr_count_total * cfg('sr-sampling', $TASK))
#				: ()
#			),
			shrimp => {
				cfg($TASK), # basic shrimp params from cfg
				'verbose' => 1,
				'log' => task_file_name(suffix => "_shrimp.log"),
				'ref' => task_file_name(".masked.fa", task => $TASKS[$TC-1] ),
				#'--al' => task_file_name(suffix => "_sr.fq"),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);

		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
	
		$LR = undef;

############################################################################		
		
		
	}elsif($TASK eq 'shrimp-ccs'){

		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}
$xf=1;
		Sam::Seq->MaxCoverage($opt_cov * $xf);
		Sam::Seq->BinSize(cfg('bin-size'));

		run_shrimp(			
			sr_files => $opt_sr_file,
			shrimp => {
				cfg($TASK), # basic shrimp params from cfg
				'verbose' => 1,
				'log' => task_file_name(suffix => "_shrimp.log"),
				'ref' => task_file_name('.fa', task => $TASKS[$TC-1] ),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);
		
		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
		$LR = undef;
		
	}elsif($TASK eq 'shrimp-finish'){

		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}
$xf=1;
		Sam::Seq->MaxCoverage($opt_cov * $xf);
		Sam::Seq->BinSize(cfg('bin-size'));


		my $sr_finish_files;

		$sr_finish_files = $opt_sr_file;
	
		# cerate a unmasked reference for finish run
		seq_filter(
                           '--in' => task_file_name('.fq', task => $TASKS[$TC-1] ),
                           '--out' => task_file_name('.unmasked.fa', task => $TASKS[$TC-1] ),
                           '--fasta' => '',
                           '--quiet' => '',
                           '--phred-offset' => 33,
		);
		
		run_shrimp(
			sr_files => $sr_finish_files,
			shrimp => {
				cfg($TASK), # basic shrimp params from cfg
				'verbose' => 1,
				'ref' => task_file_name('.unmasked.fa', task => $TASKS[$TC-1] ),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);
		
		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
		$LR = undef;
		
	}elsif($TASK eq 'blasr-unitigs'){

                # unitigs means no sampling, coverage=1 and should be run on large bin size

                Sam::Seq->MaxCoverage(1);
		Sam::Seq->BinSize(cfg('unitig-bin-size'));

                run_blasr(			
			or_files => $opt_utg_file,
                        blasr => {
				cfg($TASK), # basic shrimp params from cfg
				'log' => task_file_name(suffix => "_blasr.log"),
				'ref' => $TC < 2
                                  ? task_file_name('.masked.fa', task => $TASKS[$TC-1] )
                                  : task_file_name('.fa', task => $TASKS[$TC-1] ),
				'-nproc' => $opt_threads,
			}
		);
                
		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
		$LR = undef;
		
	}elsif($TASK =~ m/^bowtie2-/){

		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}

		Sam::Seq->MaxCoverage($opt_cov * $xf);
		Sam::Seq->BinSize(cfg('bin-size'));


		# cerate a unmasked reference for finish run
		my $ref_file;
		if($TASK =~ m/-finish$/){
			$ref_file = task_file_name('.unmasked.fa', task => $TASKS[$TC-1] );

                        seq_filter(
                                   '--in' => task_file_name('.fq', task => $TASKS[$TC-1] ),
                                   '--out' => task_file_name('.unmasked.fa', task => $TASKS[$TC-1] ),
                                   '--fasta' => '',
                                   '--quiet' => '',
                                   '--phred-offset' => 33,
                                  );
		}else{
			$ref_file = task_file_name('.masked.fa', task => $TASKS[$TC-1] )
		}

		run_bowtie2(
			sr_files => $opt_sr_file,
			bowtie2 => {
				cfg($TASK), # basic task params from cfg
				'ref' => $ref_file,
				'--threads' => $opt_threads,
				$sr_qv_offset_total == 64 
					? ('--phred64' => '') 
					: (),
			}
		);
		
		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
		$LR = undef;

	}elsif($TASK =~ m/^bwa-/){

		# configure Sam::Seq
		my $xf=1;
		if(my $x = cfg('sr-sampling',$TASK)){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}

		Sam::Seq->MaxCoverage($opt_cov * $xf);
		Sam::Seq->BinSize(cfg('bin-size'));

		# cerate a unmasked reference for finish run
		my $ref_file;
		if($TASK =~ m/-finish$/){
			$ref_file = task_file_name('.unmasked.fa', task => $TASKS[$TC-1] );

                        seq_filter(
                                   '--in' => task_file_name('.fq', task => $TASKS[$TC-1] ),
                                   '--out' => task_file_name('.unmasked.fa', task => $TASKS[$TC-1] ),
                                   '--fasta' => '',
                                   '--quiet' => '',
                                   '--phred-offset' => 33,
                                  );
		}else{
			$ref_file = task_file_name('.masked.fa', task => $TASKS[$TC-1] )
		}

		run_bwa(
			or_files => $opt_sr_file,
			sr_sampling => cfg('sr-sampling', $TASK),
			bwa => {
				cfg($TASK), # basic task params from cfg
				'ref' => $ref_file,
                                'log' => task_file_name(suffix => "_bwa.log"),
				'-t' => $opt_threads,
			}
		);
		
		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
		$LR = undef;
        }elsif($TASK =~ m/^ccs-\d+/){
            my $fqi = task_file_name('.fq', task => $TASKS[$TC-1]);
            my $fqo = task_file_name('.fq', task => $TASKS[$TC]);
            my $fmo = task_file_name('.masked.fa', task => $TASKS[$TC]);

            my @ccs_mask = split(",", cfg('hcr-mask', $TASK));
            $ccs_mask[2] = int(($ccs_mask[2] * $min_sr_length  / 100 ) +.5);
            $ccs_mask[3] = int(($ccs_mask[3] * $min_sr_length  / 100 ) +.5);
            my $ccs_mask = join(",", @ccs_mask );
            my $cmd = "$RealPerl/ccseq --threads $opt_threads <$fqi | tee $fqo | "
              ."$RealPerl/SeqFilter --phred-offset 33 --phred-mask $ccs_mask --fasta --out $fmo --base-content N";
            
            $VB->hline;
            $VB->verbose($cmd);
            qx($cmd);
            $VB->hline;
            
            $V->exit("ccseq failed: $?\n") if $?;

            $lr_chunk_offsets = chunk_index($fqo);
            
	}else{
		$VB->exit("unknown task: ".$TASK);
	}
}



# create final output
my $opt_fq_raw = task_file_name(task => '', suffix => ".untrimmed.fq");
my $opt_fa_fil = task_file_name(task => '', suffix => ".trimmed.fa");
my $opt_fq_fil = task_file_name(task => '', suffix => ".trimmed.fq");

$VS->verbose("Creating raw output sequences");

copy(task_file_name(".fq", task=>$TASKS[$TC]), $opt_fq_raw);

my $opt_chim_raw = task_file_name(task => $TASKS[$TC], suffix => ".chim.tsv");
my $opt_chim_fil = task_file_name(task => '', suffix => ".chim.tsv");

chim_filter('--in' => $opt_chim_raw, '--out' => $opt_chim_fil);


if(cfg('seq-filter')){
	$V->nline;


	if(cfg('siamaera')){
		$VS->verbose("Quality trimming and siamaera filtering raw output");
		seq_and_siamaera_filter([
			cfg('seq-filter'),
			'--substr' => $opt_chim_fil,
			'--in' => $opt_fq_raw,
                        '--phred-offset' => 33,
		],[
			cfg('siamaera'),
			'>' => $opt_fq_fil
		]);
	}else{
		$VS->verbose("Quality trimming raw output");
		seq_filter(
			cfg('seq-filter'),
			'--substr' => $opt_chim_fil,
			'--in' => $opt_fq_raw,
			'--out' => $opt_fq_fil,
                        '--phred-offset' => 33,  
		);
	}
}


if(cfg('seq-filter') && -s $opt_fq_fil){ # no need to create FASTA from empty FASTQ
	$V->nline;
	$VS->verbose("Converting to FASTA file");
	seq_filter(
                   '--in' => $opt_fq_fil,
                   '--out' => $opt_fa_fil,
                   '--fasta' => '',
                   '--phred-offset' => 33,  
	);
}


# lets see if we came this far
$no_fatal++;

# put in END to wait for memory to be cleaned


END{
	if ($no_fatal){
		unless ($opt_keep){
			$VS->verbose("Cleaning up");
			remove_tree(@tmp_dirs) 
		};
		$V->verbose("Total time spent", format => "{TIME_FULL}] {MESSAGE} {TIME_ELAPSED}\n");
		$VS->verbose("Done");
	} 
}




##------------------------------------------------------------------------##

=head1 METHODS

=cut



=head2 read_sam



=cut

sub read_sam{
	
	my %LR;
	
	# init input stream parser
	my $rsp = Sam::Parser->new(
		file => $opt_sam_file
	);
	
	# init input stream parser progess bar	
	my $pg_rsp = Verbose::ProgressBar->new(
		size => $rsp->fh
	);
	
	my $tsp = Sam::Parser->new(
		file => task_file_name(suffix => '_tmp.sam'),
		mode => '+>',
	);
	
	$VS->verbose("Reading sam file `$opt_sam_file`");
	
	# read sam header
	
	while(my %h = $rsp->next_header_line('SQ|PG')){
		$pg_rsp->update();
		# @PG
		if($h{tag} eq '@PG'){
			$PG_line = $h{raw};
			next;
		}
		$LR{$h{'SN'}} = Sam::Seq->new(
			id => $h{SN}, 
			len => $h{LN},
			sam => $tsp,	# indexed sam file, containing aln data
		);
	}
	
	# make sure SAM had header with Ref names
	$VS->exit('The SAM file needs to have a header with an reference sequence entry @SQ foreach reference sequence') 
		unless keys %LR;
	
	# read sam file
	my $rsp_c = 0;
        my $primary_aln;

	while(my $aln = $rsp->next_aln()){
	    next if $aln->is_unmapped();
            # make sure Ref Seq entry exists
            $VS->exit('The SAM file needs to have a header with an reference sequence entry @SQ foreach reference sequence')
                unless exists $LR{$aln->rname};

            # bwa does not report seq/qual for secondary alignments
            # cache the primary aln, to restore seq/qual for secondaries if necessary
            if(! $aln->is_secondary_alignment){
                $primary_aln = $aln;
            }else{
                if($aln->seq eq "*"){ # restore secondary aln seq/qual
                    $VS->exit("SAM stxarted with secondary alignment without seq/qual and without preceding primary alignment\n")
                        unless defined $primary_aln;
                    
                    $VS->exit("Secondary alignment without seq/qual and without primary alignment\n$aln")
                        unless($aln->qname eq $primary_aln->qname);
                    
                    if($aln->is_reverse_complement !=  $primary_aln->is_reverse_complement){
                        $aln->seq(Fasta::Seq->Reverse_complement($primary_aln->seq));
                        $aln->qual(reverse $primary_aln->qual);
                    }else{
                        $aln->seq($primary_aln->seq);
                        $aln->qual($primary_aln->qual);
                    }
                }
            }

            # try to add aln, if sufficient score, add to temporary sam file
            if($LR{$aln->rname}->add_aln_by_score($aln)){
                $rsp_c++;
                $tsp->append_aln($aln);
            };
            $pg_rsp->update() unless $rsp_c%10000;
	}
	$pg_rsp->finish();
	
	@LR_IDS = sort byfile keys %LR;
	
	return \%LR;
	
}



=head2 run_shrimp

Run and process shrimp

=cut

sub run_shrimp{
	my $p = {
		sr_files => [],
		sr_sampling => 0,
		shrimp => {},
		tmp_sam => task_file_name("_tmp.sam"),
		# DEPRECATED: pre-SeqChunker
		#stop_after => 0,
		@_
	};
	
	$V->nline;
	$VS->verbose("Running task ".$TASK);
	
	# Index genome file first and save projection for multiple short read
	#  files
	$VS->verbose("Indexing Long reads");
	
	# init shrimp handler
	my $shrimp_ldx = Shrimp->new( 
		%{$p->{shrimp}},
		'--save' => task_file_name("_shrimp_idx"),
		'log' => task_file_name(suffix => "_shrimp_idx.log"),
	);

	$VB->hline();
	$VB->verbose($shrimp_ldx->command());
	$VB->hline();
	
	# run shrimp
	$shrimp_ldx->run->finish;

	# init temporary sam writer
	my $tsp = $p->{ram_sam} ? undef : Sam::Parser->new(
		file => $p->{tmp_sam},
		mode => '+>',
	);


	my $sr_file_c = 0;
	my $pg_rsp;
	my $pg_step;
	
	### foreach sr file read mappings	
	foreach my $sr_file (@{$p->{sr_files}}){
		
		my $xf=1;
		if(my $x=$p->{sr_sampling}){ # adjust if sampling
			$xf = exists ${$x}{'--chunks-per-step'} 
				? ${$x}{'--chunks-per-step'} / ${$x}{'--chunk-step'}
				: 1 / ${$x}{'--chunk-step'};
		}
		my $sr_count_netto = int(($sr_count[$sr_file_c] * $xf)+0.5);
		
		# init input stream parser progess bar	
		$pg_rsp = Verbose::ProgressBar->new(size => $sr_count_netto);
		$pg_step = int(($sr_count_netto/10000)+0.5) || 1; # never be zero
		
	##	$VS->verbose("##MY COUNT IS $sr_count_netto $xf"); for comparison with older Versions
		$VS->verbose("Mapping short reads `$sr_file`");

		# init shrimp handler
		my $shrimp = Shrimp->new( 
			%{$p->{shrimp}},
			'ref' => undef,
			($p->{sr_sampling}
				? (
					'reads' => '/dev/fd/0',
					'pre_command' => seq_chunker(
						'NO_EXEC',
						$sr_file,
						%{cfg('sr-sampling', $TASK)},
					) . ' | ',
				)
				: ('reads' => $sr_file)
			),
				
			'log' => task_file_name("_shrimp_sr".$sr_file_c.".log"),
			'--progress' => $pg_step,
			'--load' => task_file_name("_shrimp_idx"),
			'-s' => undef, # cannot specify seeds when loading genome
		);
	
		$VB->hline();
		$VB->verbose($shrimp->command());
		$VB->hline();
		
		# run shrimp
		$shrimp->run;
	
		# init input stream parser
		my $rsp = Sam::Parser->new(
			fh => $shrimp->oh
		);
		
		# read the header and create $LR only on first short read file
		if($sr_file_c == 0){
			# read SAM header
			while(my %h = $rsp->next_header_line('SQ|PG')){
				# @PG
				if($h{tag} eq '@PG'){
					$PG_line = $h{raw};
					next;
				}
				$LR->{$h{'SN'}} = Sam::Seq->new(
					id => $h{SN}, 
					len => $h{LN},
					sam => $tsp,	# indexed sam file, containing aln data
				);
			}
		}
	
		# read SAM alignment section
		my $rsp_c = 0;
		my $add_c = 0;
		my $src_lib_sum = 0;
		my $src = 0;
		# shrimp log
		my $slh = $shrimp->logh;
                my $primary_aln;
                
		if($p->{ram_sam}){
			while(my $aln = $rsp->next_aln()){

                            # bwa does not report seq/qual for secondary alignments
                            # cache the primary aln, to restore seq/qual for secondaries if necessary
                            if (! $aln->is_secondary_alignment) {
                                $primary_aln = $aln;
                            } else {
                                if ($aln->seq eq "*") { # restore secondary aln seq/qual
                                    $VS->exit("SAM started with secondary alignment without seq/qual and without preceding primary alignment\n")
                                        unless defined $primary_aln;
                                    
                                    $VS->exit("Secondary alignment without seq/qual and without primary alignment\n$aln")
                                        unless($aln->qname eq $primary_aln->qname);

                                    if($aln->is_reverse_complement !=  $primary_aln->is_reverse_complement){
                                        $aln->seq(Fasta::Seq->Reverse_complement($primary_aln->seq));
                                        $aln->qual(reverse $primary_aln->qual);
                                    }else{
                                        $aln->seq($primary_aln->seq);
                                        $aln->qual($primary_aln->qual);
                                    }
                                }
                            }

				# try to add aln
				$add_c++ if($LR->{$aln->rname}->add_aln_by_score($aln));
				# monitor shrimp progress
				unless($rsp_c% $pg_step){
					seek($slh, -50, 2); # get, ..
					read($slh, my $tail, 50); # .. read, .. 
					# .. and parse last 50 chars of shrimp log for number of processed reads
					($src) = $tail =~ /(\d+)\s+\S+\s+\S+\s*$/;
					$pg_rsp->update($src) if defined $src; 
				}
				$rsp_c++;
			}
			
			seek($slh, -1500, 2); # get, ..
			read($slh, my $tail, 1500); # .. read, .. 
			# .. and parse last 1500 chars of shrimp log for number of processed reads
			my ($reads_matched) = $tail =~ /Reads Matched:\s+(\S+)/;
			$reads_matched =~ tr/,//d;
			push @sr_matched, $reads_matched;

		}else{ # create tmp sam
                        my $primary_aln;

			while(my $aln = $rsp->next_aln()){
                            # bwa does not report seq/qual for secondary alignments
                            # cache the primary aln, to restore seq/qual for secondaries if necessary
                            if (! $aln->is_secondary_alignment) {
                                $primary_aln = $aln;
                            } else {
                                if ($aln->seq eq "*") { # restore secondary aln seq/qual
                                    $VS->exit("SAM started with secondary alignment without seq/qual and without preceding primary alignment\n")
                                        unless defined $primary_aln;
                                    
                                    $VS->exit("Secondary alignment without seq/qual and without primary alignment\n$aln")
                                        unless($aln->qname eq $primary_aln->qname);

                                    if($aln->is_reverse_complement !=  $primary_aln->is_reverse_complement){
                                        $aln->seq(Fasta::Seq->Reverse_complement($primary_aln->seq));
                                        $aln->qual(reverse $primary_aln->qual);
                                    }else{
                                        $aln->seq($primary_aln->seq);
                                        $aln->qual($primary_aln->qual);
                                    }
                                }
                            }
                            
                            
                            # try to add aln, if sufficient score, add to temporary sam file
                            if($LR->{$aln->rname}->add_aln_by_score($aln)){
                                $add_c++; 
                                $tsp->append_aln($aln);
                            };
                            # monitor shrimp progress
                            unless($rsp_c% $pg_step){
                                seek($slh, -50, 2); # get, ..
                                read($slh, my $tail, 50); # .. read, .. 
                                # .. and parse last 50 chars of shrimp log for number of processed reads
                                ($src) = $tail =~ /(\d+)\s+\S+\s+\S+\s*$/;
                                $pg_rsp->update($src) if defined $src; 
                            }
                            
                            $rsp_c++;
			}

			seek($slh, -1500, 2); # get, ..
			read($slh, my $tail, 1500); # .. read, .. 
			# .. and parse last 1500 chars of shrimp log for number of processed reads
			my ($reads_matched) = $tail =~ /Reads Matched:\s+(\S+)/ || 'NA';
			$reads_matched =~ tr/,//d;
			push @sr_matched, $reads_matched;
			
		}


		# get final short read count of this file
		$pg_rsp->finish($sr_count_netto);

		# finish shrimp run
		$shrimp->finish;
		$sr_file_c++;
	}

#	$pg_rsp->finish($sr_count_total);
	
}

=head2 run_blasr

Run and process blasr

=cut

sub run_blasr{
    my $p = {
             or_files => [],
             blasr => {},
             tmp_sam => task_file_name("_tmp.sam"),
             @_
            };
	
    $V->nline;
    $VS->verbose("Running task ".$TASK);
	

    # init temporary sam writer
    my $tsp = Sam::Parser->new(
                               file => $p->{tmp_sam},
                               mode => '+>',
                              );


    my $or_file_c = 0;
    my $pg_rsp;
    my $pg_step;
	
    ### foreach sr file read mappings	
    foreach my $or_file (@{$p->{or_files}}) {
		
        my $or_count_netto = $or_count[$or_file_c];
		
        $VS->verbose("Mapping reads `$or_file`");

        my @blasr_opts;
        while(my ($k, $v) = each %{$p->{blasr}}){
            push @blasr_opts, $k, $v if $k =~ /^-/;
        }

        my $blasr_cmd = "blasr $or_file $p->{blasr}{ref} @blasr_opts -sam 2>$p->{blasr}{log}";

        $VB->hline();
        $VB->verbose($blasr_cmd);
        $VB->hline();

        open(my $blasr_oh, "-|", $blasr_cmd) or $VS->exit($!);                
		
        # init input stream parser
        my $rsp = Sam::Parser->new(fh => $blasr_oh);
		
        # read the header and create $LR only on first short read file
        if ($or_file_c == 0) {
            # read SAM header
            while (my %h = $rsp->next_header_line('SQ|PG')) {
				# @PG
                if ($h{tag} eq '@PG') {
                    $PG_line = $h{raw};
                    next;
                }
                $LR->{$h{'SN'}} = Sam::Seq->new(
                                                id => $h{SN}, 
                                                len => $h{LN},
                                                sam => $tsp, # indexed sam file, containing aln data
                                               );
            }
        }
	
        # read SAM alignment section
        my $add_c = 0;
        my $src_lib_sum = 0;
        my $src = 0;
        my $primary_aln;
        
        # create tmp sam
        while (my $aln = $rsp->next_aln()) {
            # try to add aln, if sufficient score, add to temporary sam file

            # bwa does not report seq/qual for secondary alignments
            # cache the primary aln, to restore seq/qual for secondaries if necessary
            if (! $aln->is_secondary_alignment) {
                $primary_aln = $aln;
            } else {
                if ($aln->seq eq "*") { # restore secondary aln seq/qual
                    $VS->exit("SAM started with secondary alignment without seq/qual and without preceding primary alignment\n")
                        unless defined $primary_aln;
                                    
                    $VS->exit("Secondary alignment without seq/qual and without primary alignment\n$aln")
                        unless($aln->qname eq $primary_aln->qname);

                    if($aln->is_reverse_complement !=  $primary_aln->is_reverse_complement){
                        $aln->seq(Fasta::Seq->Reverse_complement($primary_aln->seq));
                        $aln->qual(reverse $primary_aln->qual);
                    }else{
                        $aln->seq($primary_aln->seq);
                        $aln->qual($primary_aln->qual);
                    }
                }
            }
                            

            if ($LR->{$aln->rname}->add_aln_by_score($aln)) {
                $add_c++; 
                $tsp->append_aln($aln);
            }
        }

        close $blasr_oh;
        $or_file_c++;
    }
}


=head2 run_bwa

Run and process bwa

=cut

sub run_bwa{
    my $p = {
             or_files => [],
             sr_sampling => 0,
             bwa => {},
             tmp_sam => task_file_name("_tmp.sam"),
             @_
            };
	
    $V->nline;
    $VS->verbose("Running task ".$TASK);
	
    # Index genome file first and save projection for multiple short read
    #  files
    $VS->verbose("Indexing Long reads");
    
    my $bwa_index_cmd = "bwa index $p->{bwa}{ref} $p->{bwa}{ref} 2>$p->{bwa}{log}";
    
    $VB->hline();
    $VB->verbose($bwa_index_cmd);
    $VB->hline();
    
    qx($bwa_index_cmd);
    $V->exit("bwa failed: $?\n", do { local $/; local @ARGV = ("$p->{bwa}{log}") ; <> }) if $?;
    
    # init temporary sam writer
    my $tsp = Sam::Parser->new(
                               file => $p->{tmp_sam},
                               mode => '+>',
                              );

    my $or_file_c = 0;
    my $pg_rsp;
    my $pg_step;
	
    ### foreach sr file read mappings	
    foreach my $or_file (@{$p->{or_files}}) {
		
        my $or_count_netto = $or_count[$or_file_c];
		
        $VS->verbose("Mapping reads `$or_file`");

        my @bwa_opts;
        while(my ($k, $v) = each %{$p->{bwa}}){
            push @bwa_opts, $k, $v if $k =~ /^-/;
        }

        my $pre_command = "";
        my $reads;
        if($p->{sr_sampling}){
            $pre_command = seq_chunker(
                                       'NO_EXEC',
                                       $or_file,
                                       %{$p->{sr_sampling}},
                                      )
                . ' | ';

            $reads = '/dev/fd/0';
        }else{
            $reads = $or_file
        }
        
        my $bwa_cmd = $pre_command."bwa mem @bwa_opts $p->{bwa}{ref} $reads 2>$p->{bwa}{log}";

        $VB->hline();
        $VB->verbose($bwa_cmd);
        $VB->hline();

        open(my $bwa_oh, "-|", $bwa_cmd) or $VS->exit($!);                
		
        # init input stream parser
        my $rsp = Sam::Parser->new(fh => $bwa_oh);
		
        # read the header and create $LR only on first short read file
        if ($or_file_c == 0) {
            # read SAM header
            while (my %h = $rsp->next_header_line('SQ|PG')) {
				# @PG
                if ($h{tag} eq '@PG') {
                    $PG_line = $h{raw};
                    next;
                }
                $LR->{$h{'SN'}} = Sam::Seq->new(
                                                id => $h{SN}, 
                                                len => $h{LN},
                                                sam => $tsp, # indexed sam file, containing aln data
                                               );
            }
        }
	
        # read SAM alignment section
        my $add_c = 0;
        my $src_lib_sum = 0;
        my $src = 0;
        my $primary_aln;
                                                
        # create tmp sam
        while (my $aln = $rsp->next_aln()) {
            # bwa outputs unmapped reads - ignore them
	    next if $aln->is_unmapped();

            # bwa does not report seq/qual for secondary alignments
            # cache the primary aln, to restore seq/qual for secondaries if necessary
            if (! $aln->is_secondary_alignment) {
                $primary_aln = $aln;
            } else {
                if ($aln->seq eq "*") { # restore secondary aln seq/qual
                    $VS->exit("SAM started with secondary alignment without seq/qual and without preceding primary alignment\n")
                        unless defined $primary_aln;
                    
                    $VS->exit("Secondary alignment without seq/qual and without primary alignment\n$aln")
                        unless($aln->qname eq $primary_aln->qname);

                    if($aln->is_reverse_complement !=  $primary_aln->is_reverse_complement){
                        $aln->seq(Fasta::Seq->Reverse_complement($primary_aln->seq));
                        $aln->qual(reverse $primary_aln->qual);
                    }else{
                        $aln->seq($primary_aln->seq);
                        $aln->qual($primary_aln->qual);
                    }
                }
            }
            
            # try to add aln, if sufficient score, add to temporary sam file
            if ($LR->{$aln->rname}->add_aln_by_score($aln)) {
                $add_c++; 
                $tsp->append_aln($aln);
            }
        }

        close $bwa_oh;
        $V->exit("bwa failed: $?\n", do { local $/; local @ARGV = ("$p->{bwa}{log}") ; <> }) if $?;

        $or_file_c++;
    }
}


=head2 run_bowtie2

=cut

sub run_bowtie2{
		my $p = {
		sr_files => [],
		bowtie2 => {},
		tmp_sam => task_file_name("_tmp.sam"),
		stop_after => 0,
		@_
	};
	
	$V->nline;
	$VS->verbose("Running task ".$TASKS[$TC]);
	
	# Index genome file first and save projection for multiple short read
	#  files
	$VS->verbose("Indexing Long reads");
	
	# init bowtie2 handler
	my $bowtie2 = Bowtie2->new( 
		%{$p->{bowtie2}},
		'log' => task_file_name(suffix => "_bowtie2_idx.log"),
		'pre' => task_file_name("_bowtie2_idx"),
	);

	$bowtie2->bowtie2_build();

	$VB->hline();
	$VB->verbose($bowtie2->status());
	my $stdout = $bowtie2->stdout();
	$VB->verbose(join("", <$stdout>));
	my $stderr = $bowtie2->stderr();
	$VB->verbose(join("", <$stderr>));
	$VB->hline();

	$bowtie2->finish();

	
	# run bowtie2

	# init temporary sam writer
	my $tsp = $p->{ram_sam} ? undef : Sam::Parser->new(
		file => $p->{tmp_sam},
		mode => '+>',
	);


	my $sr_file_c = 0;
	my $pg_rsp;
	my $pg_step;
	
	### foreach sr file read mappings	
	foreach my $sr_file (@{$p->{sr_files}}){

		$pg_rsp = Verbose::ProgressBar->new(size => $sr_count[$sr_file_c]);
		$pg_step = int(($sr_count[$sr_file_c]/10000)+0.5) || 1; # never be zero
		
		$VS->verbose("Mapping short reads `$sr_file`");

		# init shrimp handler
		$bowtie2->bowtie2( 
			%{$p->{bowtie2}},
			'ref' => undef,
			'-x' => task_file_name("_bowtie2_idx"),
			'-U' => $sr_file,
		);

		$VB->verbose($bowtie2->status); 

		# init input stream parser
		my $rsp = Sam::Parser->new(
			fh => $bowtie2->stdout,
		#	is => sub{! $_[0]->is(UNMAPPED)}
		);
		
		# read the header and create $LR only on first short read file
		if($sr_file_c == 0){
			# read SAM header
			while(my %h = $rsp->next_header_line('SQ|PG')){
				# @PG
				if($h{tag} eq '@PG'){
					$PG_line = $h{raw};
					next;
				}
				$LR->{$h{'SN'}} = Sam::Seq->new(
					id => $h{SN}, 
					len => $h{LN},
					sam => $tsp,	# indexed sam file, containing aln data
				);
			}
		}
		
		# read SAM alignment section
		my $rsp_c = 0;
		my $add_c = 0;
		my $src_lib_sum = 0;
		my $src = 0;
		# shrimp log
		my $slh = $bowtie2->stderr;
		my $primary_aln;
                
		while(my $aln = $rsp->next_aln()){
			next if $aln->rname() eq '*';

                        # bwa does not report seq/qual for secondary alignments
                        # cache the primary aln, to restore seq/qual for secondaries if necessary
                        if (! $aln->is_secondary_alignment) {
                            $primary_aln = $aln;
                        } else {
                            if ($aln->seq eq "*") { # restore secondary aln seq/qual
                                $VS->exit("SAM started with secondary alignment without seq/qual and without preceding primary alignment\n")
                                    unless defined $primary_aln;
                                
                                $VS->exit("Secondary alignment without seq/qual and without primary alignment\n$aln")
                                    unless($aln->qname eq $primary_aln->qname);

                                if($aln->is_reverse_complement !=  $primary_aln->is_reverse_complement){
                                    $aln->seq(Fasta::Seq->Reverse_complement($primary_aln->seq));
                                    $aln->qual(reverse $primary_aln->qual);
                                }else{
                                    $aln->seq($primary_aln->seq);
                                    $aln->qual($primary_aln->qual);
                                }
                            }
                        }

                        # try to add aln, if sufficient score, add to temporary sam file
			if($LR->{$aln->rname}->add_aln_by_score($aln)){
				$add_c++; 
				$tsp->append_aln($aln);
			};
			$rsp_c++;
		}

		$VB->hline();
		my $stderr = $bowtie2->stderr();
		$VB->verbose(join("", <$stderr>));
		$VB->hline();

		# finish shrimp run
		$bowtie2->finish;
		$sr_file_c++;
	}
}


=head2 create_sorted_sam

=cut

sub create_sorted_sam{
	my $opt_sam_out = task_file_name(".sam");
	
	$V->nline;
	$VS->verbose("Creating filtered sam `$opt_sam_out`");
	
	open(OUT, '>',$opt_sam_out) or $VB->exit($!);
	
	my @lr_ids;
	# header section
	printf OUT ("\@HD\tVN:%s\tSO:%s\n", "unknown", "unknown");
	foreach my $pb_id (@LR_IDS){
		if (defined $LR->{$pb_id}){
			push @lr_ids, $pb_id;
			printf OUT ("\@SQ\tSN:%s\tLN:%s\n", $pb_id, $LR->{$pb_id}->len);
		}else{
			push @LR_IDS_IGNORED, $pb_id;
			# $V->exit("Lost read $pb_id");
		}
	}
	
	@LR_IDS = @lr_ids;
	
	# header @PG
	print OUT $PG_line;
	
	# init input stream parser progess bar	
	my $pgb = Verbose::ProgressBar->new(size => scalar @LR_IDS);
	
	my @chunk_idxs;
	# alignment section
	my $pb_c = 0;
	foreach my $pb_id (@LR_IDS){
		push @chunk_idxs, tell(OUT) unless $pb_c % cfg('chunk-size');

		foreach my $aln($LR->{$pb_id}->alns($opt_sort_sam_by_coords)){
			# write to sam
			print OUT "$aln";
			# write to LR wise FASTQ
		}
		$pgb->update($pb_c);
		$pb_c++;
	}
	$pgb->finish($pb_c);
	
	close OUT;
	
	return \@chunk_idxs;
}






=head2 read_long

Read the pacbio long read file and create a new, indexed long read file,
 ordered the same way as the sorted sam files.

=cut

sub read_long{

	$VS->verbose("Preparing long reads");

	# read fasta/fastq, write and sort by id
	my %lr;

	my $lrpw;

	foreach(@$opt_lr_file){
		
		my $lrpr;
		$lrpr = Fasta::Parser->new(file => $_)->check_format();
		$lrpr = Fastq::Parser->new(file => $_)->check_format() unless $lrpr;
		$lrpr || $VS->exit("Unknown format in '--long-read' file `$_`");
		
		my $lr_count = $lrpr->guess_seq_count();
		push @lr_count, $lr_count;
		my ($lr_length, $lr_dev) =  $lrpr->guess_seq_length;
		push @lr_length, $lr_length;
		push @lr_bps, ($lr_length * $lr_count);
		

                $lrpw = Fastq::Parser->new( 
                                           file => task_file_name(".fq", task => $TASKS[$TC] ), 
                                           mode => '+>'
                                          );

		if(ref $lrpr eq 'Fasta::Parser'){ # FASTA ref
			
			my $fi_file = task_file_name(suffix => ".ignored.tsv", task => '');
			my $stubby_count = 0;
			open(IGNORE, '>>', $fi_file) or $VS->exit($!." $fi_file");
			while(my $lr = $lrpr->next_seq){
				if(length($lr->seq) < 2*$min_sr_length){
					$stubby_count++;
					printf IGNORE "%s\t%s\n", $lr->id, "stubby";
					next;
				}
				if(exists $lr{$lr->id}){
					$VS->exit('Non-unique long read id ('. $lr->id .') in '. $_);
				}

				$lr{$lr->id} = Fastq::Seq->new(
                                                               '@'.substr($lr->seq_head,1),
                                                               $lr->seq,
                                                               "+",
                                                               '$'x length($lr->seq)
                                                              );
                        }
			close IGNORE;
			$V->verbose("Skipped $stubby_count stubby reads with length <".2*$min_sr_length) if $stubby_count;
			
		}else{ # FASTQ ref
			if($opt_mode eq 'external-sam'){
				my $po = $lrpr->guess_phred_offset || $opt_lr_qv_offset;
				$V->exit("Cannot guess phred offset from provided reference file, please specify --lr-qv-offset")
					unless $po;
				$V->exit("Only offset 33 and 64 are supported")
					unless $po;
					
				$lrpr->phred_offset($po);
				
				while(my $lr = $lrpr->next_seq){
					if(exists $lr{$lr->id}){
						$VS->exit('Non-unique long read id ('. $lr->id .') in '. $_);
					}
					# convert seq to lower case, allow HCRs in external-sam
					$lr->phred_transform if $po == 64;
					$lr{$lr->id} = $lr;
                                }
				
			}else{
				
				my $fi_file = task_file_name(suffix => ".ignored.tsv", task => '');
				my $stubby_count = 0;
				open(IGNORE, '>>', $fi_file) or $VS->exit($!." $fi_file");
				while(my $lr = $lrpr->next_seq){
					if(length($lr->seq) < 2*$min_sr_length){
						$stubby_count++;
						printf IGNORE "%s\t%s\n", $lr->id, "stubby";
						next;
					}
					if(exists $lr{$lr->id}){
						$VS->exit('Non-unique long read id ('. $lr->id .') in '. $_);
					}
					# convert FASTQ to FASTA
					$lr{$lr->id} = $lr;
				}
				close IGNORE;
				$V->verbose("Skipped $stubby_count stubby reads with length <".2*$min_sr_length) if $stubby_count;
				
			}
		}
	}


        
        
	# write sorted/indexed fq/fa lr file for mapping/sam2cns
	my @lr_idxs;
	my $lr_c = 0;
	@LR_IDS = sort byfile keys %lr;
	foreach(@LR_IDS){
		my $pos = $lrpw->append_seq($lr{$_});
		push @lr_idxs, $pos unless $lr_c % cfg('chunk-size');
		$lr_c++;
	}

        seq_filter(
                   '--in' => $lrpw->{file},
                   '--out' => task_file_name('.masked.fa', task => $TASKS[$TC] ),
                   '--fasta' => '',
                   '--quiet' => '',
                   '--lower-case' => '',
                   '--phred-offset' => 33,
                  );
        
	return \@lr_idxs;
}



=head2 correct_sr_mt

=cut

sub correct_sr_mt{
	my ($sam_chunk_offsets, $lr_chunk_offsets) = @_;
	
	print $TASK,"\n";
	
	$V->nline;
	$VS->verbose("Correcting Sequences (".@$sam_chunk_offsets." batches)");
	
	# pbc_correct.pl 
	my %pbc_default = (
		'--sam' 		=> task_file_name(".sam"),
		'--max-reads'	=> cfg('chunk-size'),
		'--coverage'	=> $opt_cov,
		'--append'		=> 1,
		'--cfg'	=> $cfg || undef,		
		'--mask-weak-reads' => cfg('mask-weak-reads', $TASK),
		'--ignore-weak-reads' => cfg('ignore-weak-reads', $TASK), 

		cfg('detect-chimera', $TASK) ? ('--detect-chimera' => '') : (), 
		cfg('hcr-ignore', $TASK) ? ('--ignore-hcr' => '') : (),
		 
		@$opt_lr_file
			? ('--ref' => task_file_name(".fq", task => $TASKS[$TC-1] ))
			: (),
			
		$TASK =~ m/iter-1|pre-\d/ # calculate hcrs on first iter for second iter
			? ('--sr-min-length' => $min_sr_length) # params from config
			: ('--hcr-min-ratio' => 0), # deactivate on finish/sam
			'--lcr-end-ratio' => cfg('lcr-end-ratio', $TASKS[$TC]),

		($TASK =~ /-finish/) # calculate hcrs on first iter for second iter
			? (
                           '--max-ins-length' => 0,
                           '--no-use-ref-qual' => '',
                           '--ignore-hcr' => '',
			  ) # params from config
			: (),

		($TASK eq 'read-sam') # calculate hcrs on first iter for second iter
			? (@$opt_lr_file ? ()	: ('--ignore-hcr' => 1),
 				'--max-ins-length' => 0,
			  ) # params from config
			: (),
		
	);
	
	my $pbc_cmds = '';
	
	# generate xargs statements foreach chunk
	for(my $ci=0; $ci<@$sam_chunk_offsets; $ci++){
		my %pbc_config = (
			%pbc_default,
			'--prefix'		=> task_file_name(".".$ci),
			'--sam-offset' => $sam_chunk_offsets->[$ci], 
			'--ref-offset' => $lr_chunk_offsets->[$ci],
			'--qv-offset' => 33,
		);
		
		# params
		$pbc_cmds.= param_join(\%pbc_config)."\n";
	}
	
	# write cmd file
	
	my $cfg_file = task_file_name(".cmds");
	open(CFG, '>', $cfg_file) or $VS->exit($!);
	print CFG $pbc_cmds;
	close CFG;
	
	# xarg cmds, capture stderr;
	my $xgr;
	open($xgr, "(cat $cfg_file | xargs -P $opt_threads -L 1 -t $RealPerl/sam2cns) 2>&1 |")
		or $VS->exit($!);
	
	$VB->hline();
	# 
	my $bc;
	my $bs = "Batch %d/".@$sam_chunk_offsets;
	while(<$xgr>){
		chomp();
		if ($_ =~ /^perl /){
			$VS->verbose(sprintf($bs, ++$bc));
			$VB->verbose($_);
			$VB->hline() 
		}else{
			$VB->verbose($_);
		}
		
		if(/xargs:.*255/){
			$VS->exit("sam2cns returned with error");
		}
	}
	
	
	$VS->verbose("Merging corrected output");
	my $fq_file = task_file_name(".fq");
	my $fq_glob = task_file_name(".[0-9]*.fq");
	my $fa_file = task_file_name(".masked.fa");
#	my $fa_glob = task_file_name(".[0-9]*.masked.fa");
	my $fi_file = task_file_name(suffix => ".ignored.tsv", task => '');
	my $fi_glob = task_file_name(".[0-9]*.ignored.tsv");
	my $fc_file = task_file_name(".chim.tsv");
	my $fc_glob = task_file_name(".[0-9]*.chim.tsv");
	
	my @fq_glob = sort byfile glob $fq_glob;
#	my @fa_glob = sort byfile glob $fa_glob;
	my @fi_glob = sort byfile glob $fi_glob;
	my @fc_glob = sort byfile glob $fc_glob;
#	my $fq_glob_sorted = join(" ", @fq_glob);
#	my $fa_glob_sorted = join(" ", @fa_glob);
#	my $fi_glob_sorted = join(" ", @fi_glob);
#	my $fc_glob_sorted = join(" ", @fc_glob);
	
	# create offset idx for reference
	my @ref_idxs = (0);
	my $offset = 0;
	# get fq indexes
	foreach(@fq_glob){
		$offset+= -s $_;
		push @ref_idxs, $offset;   
	}
	
	# remove last one, its just the eof
	pop(@ref_idxs);
	
	qx(>$fq_file); # create empty file, just to be safe
	qx(>$fa_file);
	# $fi_file gets appended over iters
	qx(echo -e "#id\tfrom\tto\tscore" > $fc_file); # create file with header
	for (my $i=0;$i<@fq_glob;$i+=500){
	    my $f = 0+$i;
	    my $t = 499+$i > $#fq_glob ? $#fq_glob : 499+$i;

	    system("cat ".join(" ", @fq_glob[$f..$t])." >>$fq_file") && die $!;
#	    system("cat ".join(" ", @fa_glob[$f..$t])." >>$fa_file") && die $!;
	    system("cat ".join(" ", @fi_glob[$f..$t])." >>$fi_file") && die $!;
	    system("cat ".join(" ", @fc_glob[$f..$t])." >>$fc_file") && die $!;
	}

	
	unlink @fq_glob unless $opt_keep > 1;
#	unlink @fa_glob unless $opt_keep > 1;
	unlink @fi_glob unless $opt_keep > 1;
	unlink @fc_glob unless $opt_keep > 1;

        # Masking
        my @hcr_mask = split(",", cfg('hcr-mask', $TASK));
        $hcr_mask[2] = int(($hcr_mask[2] * $min_sr_length  / 100 ) +.5);
        $hcr_mask[3] = int(($hcr_mask[3] * $min_sr_length  / 100 ) +.5);
        my $hcr_mask = join(",", @hcr_mask );
        my $cmd = "$RealPerl/SeqFilter $fq_file --out $fa_file --phred-offset 33 --phred-mask $hcr_mask --fasta --base-content N";
        
        $VB->hline;
        $VB->verbose($cmd);
        qx($cmd);
        $VB->hline;
        
        $V->exit("SeqFilter failed to mask $fq_file: $?\n") if $?;

	
	return \@ref_idxs;
}

=head2 file_name

Create a file name depending on current $TC and $opt_prefix

  $TC = 1;
  $opt_prefix = "/foo";
  task_file_name(".suf"); # $TASKS[$TC]
    # "/foo_shrimp-iter-1.suf"
  task_file_name(".suf", prefix => "/foo/bar", task => 'custom');
    # "/foo_custom/bar_custom.suf"

=cut


sub task_file_name{
	my $p = {
		root => $opt_prefix,
		task => $TASKS[$TC || 0],
		prefix => $opt_prefix,
		suffix => (@_%2 ? shift : ''),
		@_
	};
	
	my $tfn = sprintf('%1$s/%2$s/%3$s%4$s', $p->{root}, $p->{task}, $p->{prefix}, $p->{suffix});
	$tfn =~ tr{/}{}s;
	return $tfn;
}


=head2 chunk_index

=cut

sub chunk_index{
    my $file = shift;
    my $fp;
    $fp = Fasta::Parser->new(file => $file)->check_format();
    $fp = Fastq::Parser->new(file => $file)->check_format() unless $fp;
    $fp || $VS->exit("Unknown format in file `$file`");

            
    # write sorted/indexed fq/fa lr file for mapping/sam2cns
    my @lr_idxs = (0);
    my $lr_c = 1;
    while($fp->next_seq){
        my $pos = $fp->append_tell();
        push @lr_idxs, $pos unless $lr_c % cfg('chunk-size');
        $lr_c++;
    }
    return \@lr_idxs;
}

=head2 create_custom_cfg

=cut

sub copy_custom_cfg{
	my ($cfg_core_file, $cfg_custom_file) = @_;	
	open(COR, $cfg_core_file) or $VS->exit($!);
	open(CUS,'>',$cfg_custom_file) or $VS->exit("Couldn't create config file `$cfg_custom_file`");
	
	while(<COR>){
		if(/^#/){
			next unless /^##/; 
			print CUS $_;
		}else{
			if(/^\s*$/){
				print CUS $_;
			}else{
				print CUS '#',$_; 
			}
		}
	}
	
	close COR;
	close CUS;		
}


=head2 chim_filter

Run ChimeraToSeqFilter on raw chimera output

=cut

sub chim_filter{

	my %params = (cfg('chimera-filter'), @_);
	my $params = param_join(\%params);

	my $cmd_chim_fil = "$RealPerl/ChimeraToSeqFilter.pl $params";
	
	$V->nline;
	$VS->verbose("Filtering chimera annotations");
	$VB->hline;
	$VB->verbose($cmd_chim_fil);
	qx($cmd_chim_fil);
	$VB->hline;
	
}


=head2 seq_chunker

Run SeqChunker. NO_EXEC as first param to only get command.

=cut


sub seq_chunker{
	my $no_exec;
	if($_[0] eq 'NO_EXEC'){
		shift @_;
		$no_exec++;
	}
	my @files;
	while($_[0] && $_[0] !~ /^-/){
		push @files, shift @_;
	}
	
	my %params = @_;
	my $params = param_join(\%params);
	my $files = join(" ", @files);
	my $cmd = "$RealBin/SeqChunker $params $files";
	
	return $cmd if $no_exec;
	
	$VB->hline;
	$VB->verbose($cmd);
	qx($cmd);
	$VB->hline;
}

=head2 seq_filter

Run SeqFilter on raw output

=cut


sub seq_filter{
	my %params = @_;
	my $params = param_join(\%params);

	my $cmd = "$RealPerl/SeqFilter $params";
	
	$VB->hline;
	$VB->verbose($cmd);
	qx($cmd);
	$VB->hline;
}

=head2 seq_and_siamaera_filter

Run seqfilter and siamaera on trimmed output

=cut


sub seq_and_siamaera_filter{
	my %seq_params = @{$_[0]};
	my $seq_params = param_join(\%seq_params);

	my %siam_params = @{$_[1]};
	my $siam_params = param_join(\%siam_params);

	my $cmd = "$RealPerl/SeqFilter $seq_params --out - | $RealPerl/siamaera $siam_params";
	
	$VB->hline;
	$VB->verbose($cmd);
	qx($cmd);
	$VB->hline;
}


=head2 byfile

Sort function for "natural" filesorting, descending.

=cut

sub byfile {
  my @a = split /(\d+)/, $a;
  my @b = split /(\d+)/, $b;
  my $M = @a > @b ? @a : @b;
  my $res = 0;
  for (my $i = 0; $i < $M; $i++) {
    return -1 if ! defined $a[$i];
    return 1 if  ! defined $b[$i];
    if ($a[$i] =~ /\d/) {
      $res = $a[$i] <=> $b[$i];
    } else {
      $res = $a[$i] cmp $b[$i];
    }
    last if $res;
  }
  $res;
}

=head2 is_empty_dir

Check whether a folder contains any files.

=cut

sub is_empty_dir {
    my $dirname = shift;
    opendir(my $dh, $dirname) or die "Not a directory";
    return scalar(grep { $_ ne "." && $_ ne ".." } readdir($dh)) == 0;
}


=head2 param_join (HASHREF, JOIN=STRING)

Joins a HASHREF to a parameter string with JOIN [" "], ignoring keys with 
 undef values and creating flag only values for ''.

  param_join(HASHREF); # join with space
  param_join(HASHREF, join => "\n") # join with newline

=cut

sub param_join{
	my %params = %{shift @_};
	my $p = {
		'join' => " ",
		@_
	};
	
	# params
	my @params;
	my $params;
	foreach my $k (sort keys %params){
		my $v = $params{$k};
		# flag only is '', NOT '0' !!!
		next unless defined ($v);
		push @params, ($v ne '') ? ($k, $v) : $k;
	}
	$params .= join($p->{'join'}, @params);
	return $params;
}


=head2 cfg

Return parameter settings from %cfg w/r/t given task and global options

  $cfg{<PARAM>} = {
	DEF => 12, # global default
	<TASK1> => 8, # task specific settings, overuling global
	<TASK2> => 9, # task specific settings, overuling global
	<TASK2> => 0, # task specific settings, overuling global
  }
  
  $param = cfg(PARAM);        # 12
  $param = cfg(UNKNOWN_PARAM) # undef
  # by TASK_ID
  $param = cfg(PARAM,TASK1);  # 8
  $param = cfg(PARAM,TASK3)   # 12 (fall back to global)
  # by TASK_COUNT
  $param = cfg(PARAM, 1)      # 8 (first task in @TASK)
  $param = cfg(PARAM, -1)     # 0 (last task in @TASK)

=cut


sub cfg{
	my ($k, $t) = @_;
	return undef unless exists $cfg{$k};
	return $cfg{$k} unless ref $cfg{$k};
	
	if(ref $cfg{$k} eq "ARRAY"){
		return wantarray ?	@{$cfg{$k}} : $cfg{$k};
	}
	
	if(! exists $cfg{$k}{DEF}){
		return wantarray ?	%{$cfg{$k}} : $cfg{$k};
	}
	
	my %p = %{$cfg{$k}};
	return undef unless %p;
	
	my $v = exists $p{DEF} ? $p{DEF} : undef;
	
	if(defined $t){
		if($t =~ /[^-0-9]/){
			$v = $p{$t} if exists $p{$t};
		}else{
			$v = $p{$TASKS[$t]} if exists $p{$TASKS[$t]};
		}
	}
	return $v;
}

################
## DEPRECATED ##
################

=pod

#=head2 correct_sr_st
#=cut
#

sub correct_sr_st{
	my ($ref, $sam_out) = @_;
	
	# pbc_correct.pl 
	my %pbc_default = (
		'--sam' 		=> $sam_out,
		'--coverage'	=> $opt_cov,
		'--ref' 		=> undef,
		'--prefix'		=> undef,
		'--ignore-hcr'	=> 1,
		'--append'		=> 1,
		$cfg
		 	? ('--cfg'	=> $cfg) 
		 	: (),
	);
	
	my @pbc_keys = sort keys %pbc_default;
	
	my $pbc_cmds = '';
	
	# generate cmd foreach chunk
	my %pbc_config = (
		%pbc_default,
		'--prefix'		=> task_file_name(".".threads->tid()),
		'--ref' 		=> $ref,
	);
	
	# params
	my @pbc_cmd;
	foreach my $k (@pbc_keys){
		my $v = $pbc_config{$k};
		# flag only is undef or '', NOT '0' !!!
		push @pbc_cmd, (defined($v) && $v ne '') ? ($k, $v) : $k;
	}
	$pbc_cmds = sprintf("perl $RealBin/sam2cns %s |",  join(" ", @pbc_cmd));
	
	$VB->hline;
	$VB->verbose($pbc_cmds);
	
	my $xgr;
	open($xgr, $pbc_cmds)
		or $VB->exit($!);
	
}



#=head2 coverage_tables
#
#=cut

sub coverage_tables{
	my $opt_fq_out = task_file_name("fq");
	
	# progess bar	
	my $pgp = Verbose::ProgressBar->new(
		size => scalar keys %$LR
	);

	$VB->verbose("Calculating exact coverage by score tables ".$opt_fq_out);

	my $i=1;
	while(my ($pb_id, $pb) = each %$LR){
		my @COV;
		my $ofh;
		if($opt_fq_out eq '-'){
			$ofh = \*STDOUT;
		}else{
			open($ofh, '>', task_file_name('_'.$i.'.tsv')) or $VB->exit($!);
		}
		foreach my $score_co(1..1000){
			$pb->is(sub{ 
				my $score = $_[0]->opt('AS');
				return $score == $score_co
			});
			# add to previous cov
			push @COV, [$pb->coverage];
		}
		print $ofh join("\t", @$_)."\n" for @COV;
		close $ofh if $opt_fq_out ne '-';
		
		$pgp->update($i++);
	}
	$pgp->finish($i);


	#printf $ofh ("\@%s\n%s\n+\n%s\n", $pb->consensus);
	#my @cov = $pb->coverage;
	#my @cov1 = grep{defined($_) && $_>0}@cov;
	#
	#print "#"x30, "\n";
	#printf "%-8s %6.1f\n", 'Score:', $score_co; 
	#next unless @cov;
	##printf join(" ", @cov), "\n";
	#printf "%-8s %6.1f%%\n", 'Covered:', (@cov1/$pb->len)*100,
	#printf "%-8s %6.1f\n", 'Mean:', sum(@cov)/@cov;
	#printf "%-8s %6.1f\n", 'Max:', max(@cov);
	#printf "%-8s %6.1f\n", 'Cols:', scalar @cov;

}


=cut





##------------------------------------------------------------------------##

=head1 AUTHORS

=over

=item * Thomas Hackl, thomas.hackl@uni-wuerzburg.de

=back
