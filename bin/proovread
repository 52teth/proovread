#!/usr/bin/env perl

##------------------------------------------------------------------------##
# LICENCE
#
#
# $Id$
#
##------------------------------------------------------------------------##

use warnings;
use strict;

use Getopt::Long;
use Pod::Usage;
use List::Util qw(sum max);

use File::Basename;
use File::Path qw(make_path remove_tree);
use File::Copy;
use FindBin qw($RealBin);

use lib "$RealBin/../lib/";

use Verbose;
use Verbose::ProgressBar;

use Fastq::Parser 0.07;
use Fastq::Seq;

use Fasta::Parser 0.08;
use Fasta::Seq;

use Sam::Parser;
use Sam::Alignment;
use Sam::Seq 0.08;

use Shrimp 0.06;

use threads;
use Thread::Queue;
use Time::HiRes qw(usleep);

use Data::Dumper;

our $VERSION = '0.83';
our ($REVISION) = '$Revision$' =~ /(\d+)/;
our ($MODIFIED) = '$Date$' =~ /Date: (\S+\s\S+)/;


=head1 NAME

proovread

=cut

=head1 DESCRIPTION

Correct single molecule sequencing reads by iterative mapping of high
 throughput sequencing reads.

=cut

=head1 CHANGELOG

=head2 0.83

=over

=item [BugFix] Only processed first of multiple short read files in mapping.
 Fixed this here, requires Shrimp-0.06, to store genome projections in between
 short read runs.

=item [Feature] Chimera detection.

=back

=head2 0.82

=over

=item [BugFix] C<$pg_step> is used in modulo, cannot be 0.

=item [Change] sam2cns-0.04 C<--lcr-min-length> calculated from mean short
 read length

=item [Feature] verbose print cfg and commandline parameter

=item [BugFix] Incorrect parameter for sam2cns, fix by new method 
 C<param_join()>  

=item [BugFix] --ignore-sr-length did not work and ccs expected 
 length was increased to 1000

=item [Feature] external-sam mode

=item [Feature] FastqFilter.pl default settings from config.

=item [Feature] FastqFilter.pl is automatically run on results to produce
 a trimmed output.
 
=back


=head2 0.81

=over


=item [Change] Cleaned up verbose messages. 

=item [Feature] Final finishing task using aligned and dumped short reads 
 from previous runs to further increase accuracy.

=item [Feature] Support of multiple short and long read files at the same time.

=back


=head2 0.80

=over

=item [Change] Prefix defaults to proovread_<TIMESTAMP>.

=item [Feature] Scripts stops if output directory cannot be created/
 is not empty.

=item [Change] Chunk files have natural consecutive numbering scheme
 and are sorted using C<byfile()> to keep there order consistent. This
 makes the chunk filename robust for any number of chunks.

=item [Feature] C<byfile()> sorting function for "natural" file sorting

=item [Refactoring] Changed PASS based workflow to TASK based 
 workflow, where tasks can be modularily put together to adjust for
 different scenarios. TASK order can easily configured via the 
 config file.

=item [Feature] Config provides 'modes', which essentially are 
 templates running specific TASKs for different scenarios. 

=back

=head2 0.72

=over

=item [Feature] Added C<sr-trim> and C<sr-indel-taboo> to advanced
 config options

=item [Change] Uses Sam::Seq 0.08, which provides InDelTabooLength based 
 short read trimming to reduce errors especially in edge regions

=item [Change] Binary path is now determined by $FindBin::Realbin instead of
 $FindBin::Bin. Robust against linking the binary.

=item [Feature] Read short reads FASTA input

=item [Change] remove_tree moved to END{}, to delete folders also in case of 
 an error

=item [BugFix] Bad rounding, $pg_step could become 0, does not work in modulus

=back

=head2 0.71

=over

=item [Feature] Test config file for existence before loading.

=item [Feature] proovread now reads all parameter from a default core config
 (proovread.cfg). Additionally an optional, customized config file can be
 generated for user modification C<< --create-cfg >> and the modified config
 can be provided to the pipeline with C<< -c/--cfg >>. Highest controll 
 priority remains with the scripts command line parameter, yet the configs 
 manipulate the defaults and allow additional advanced settings, like shrimp
 mapping parameter, which cannot be controlled via command line. 

=back

=head2 0.70

=over

=item [Feature] Shrimp progress bar now displays to actual precentage of 
 mapped reads und computes ETA, using the --sr-count guess and on the fly
 parsing of the Shrimp progress from the Shrimp log file.

=item [Feature] "--sr-count" with auto-guess, used for eta calculations.

=item [Feature] "--sr-length" with auto-guess.

=item [Feature] "--sr-qv-offset" with auto-guess.

=item [Renaming] "--qv-offset" to "--sr-qv-offset" 

=item [Renaming] "--reads" to "--short-reads" and "--ref" to "--long-reads"

=item [Change] C<--qv-offset> is now required without default. 

=item [Change] Rearranged parameter specs, removed parameter currently not working/under
 development.

=item [Renaming] <reads> variables to <sr>, <ref> to <lr>.

=item [Change] Default C<--full-threshold> to 55%,35%.

=item [Change] Reduced gap extension costs for shrimp by one to prevent 
 misalignments of Triplet/... insertions in variants and to account
 for slight bias towards homopolymer errors.

=back

=head2 0.60

=over

=item [Bugfix] --reads did not recycle value, if only one set was given and 
 multiple passes are run.

=item [Refactoring] Versionized.

=back

=cut

=head1 TODO

=over

=item masking stats -> FastaFilter

=item dont overwrite output

=item dont write to existing folders

=back

=cut

##------------------------------------------------------------------------##

my $no_error;

# verbose
my $V = Verbose->new(
	format => "  {MESSAGE}\n",
	line_width => 80,
);

# verbose
my $VS = Verbose->new(
	format => "[{TIME_FULL}] {MESSAGE}\n",
	line_width => 80,
);

# verbose bash style
my $VB = Verbose->new(
	line_delim => "\\\n",
	line_width => 80,
	format => "{MESSAGE}\n",
);

$VB->verbose("$0-$VERSION, rev$REVISION, $MODIFIED");


=head1 OPTIONS

=cut

=over

=cut

# load core defaults
$VS->verbose("Reading core config");
my $cfg_core_file = "$RealBin/../proovread.cfg"; 
my %cfg = do $cfg_core_file;

=item [--create-cfg=<CFGFILENAME>] [<CWD>/proovread_cfg.pm]

Create a custom config file. Unless you provide a PATHNAME, defaults to 
 CWD/proovread.cfg. Does not run the pipeline. The custom config file 
 can be modified/renamed and supplied to the pipeline using -c/--cfg. The
 config file is optional, supercedes default parameters, but has lower 
 priority than command line options. The config fall also allows control
 of advanced options, not available via command line. For details, create
 a config file and have a look at its header section.

=item [-c, --cfg]

Custom config file.

=cut

# load user defaults and overwrite core
my $cfg;
for(my $i=0; $i<@ARGV; $i++){
	if($ARGV[$i] =~ /--create-cfg$/){
		my $cfg_custom_file = $i < $#ARGV ? $ARGV[$i+1] : basename($cfg_core_file);
		$VS->verbose("Creating custom config file: $cfg_custom_file");
		copy_custom_cfg($cfg_core_file, $cfg_custom_file);
		exit(0);
	}
	if($ARGV[$i] =~ /-c$|--cfg$/){
		$cfg = $ARGV[$i+1];
		last;
	}
}

if($cfg){
	unless(-e $cfg){
		$VS->exit("Cannot find config file: $cfg");
	}
	$VS->verbose("Reading custom config: $cfg");
	%cfg = (%cfg, do "$cfg"); 
}

$VS->verbose("Reading command line options");

# load cmd options and overwrite defaults
my %opt;

$opt{'c|cfg=s'} = \$cfg;

=item -l, --long-reads=<PATHNAME>

Pacbio reads file to correct. FASTA or FASTQ format. To correct
 mulitple files at once, provide parameter mulitple times.
 
  -l cell1 -l cell2 ... # correct 2 cells at once

=cut

$opt{'l|long-reads=s@'} = \(my $opt_lr_file = $cfg{'long-reads'});

=item -s, --short-reads=<PATHNAME>

High confidence short reads file used for correction in FASTQ or
 FASTA format.
To correct with mulitple files at once, provide parameter mulitple
 times.

NOTE: If multiple libraries are provided, they need to be of the 
 same format (FASTA or FASTQ) and quality offset (33,64...)
 respectively.

  -s lib1 -s lib2 # use reads from to libraries for correction

=cut

$opt{'s|short-reads=s@'} = \(my $opt_sr_file = $cfg{'short-reads'});

=item [-p, --prefix=<STRING>]

Prefix to output files. Defaults to 'proovread'.

=cut

$opt{'p|prefix=s'} = \(my $opt_prefix = $cfg{'prefix'});

=item [--coverage=<INT>] [50]

Coverage cutoff for highest scoring mappings at each location.

=cut

$opt{'coverage=s'} = \(my $opt_cov = $cfg{'coverage'});

=item [-t, --threads] [8]

Number of threads to use for mapping. Defaults to 8 (or maximum available 
 number of processors, if kess than 8 availabe).

=cut

$opt{'t|threads=i'} = \(my $opt_threads = $cfg{'threads'});

=item [-m, --mode] [auto]

Running mode of the pipeline, accepted values are 
 'pacbio-iterative', 'pacbio-ccs', 'external-sam'. By default, the
 most appropriate mode is choosen based on the provided input data.
 See manual for further information. 

=cut

$opt{'m|mode=s'} = \(my $opt_mode);

=item [--sam] [8]

External SAM file to compute corrected consensus sequences from. 
 Provide as input instead of --long-reads/--short-reads. Automatically
 sets --mode to 'external-sam'.
 
=cut

$opt{'sam=s'} = \(my $opt_sam = $cfg{'sam'});

=item [--ram-sam] [OFF]

By default, while mapping, a temporary SAM file is created and an index to
 this file is kept in store. This limits the memory requirement for one SMRT
 cell (>100Mbp, 50X coverage) to less than 10Gb. 

Specify '--ram-sam' to hold the SAM presentation entirely in memory. This is
 faster and saves disk space, but might require up to 100GB per SMRT cell. 

=cut

$opt{'ram-sam'} = \(my $opt_ram_sam = $cfg{'ram-sam'});

=item [--sort-sam-by-coordinates] [OFF]

Sort the filtered SAM files by coordinates in addition to the 
 sorting of references. This has no effect on the pipeline, just 
 a convenience if you need the files for something else.

=cut

$opt{'sort-sam-by-coordinates'} = \(my $opt_sort_sam_by_coords = $cfg{'sort-sam-by-coordinates'});

=item [--keep-temporary-files] [OFF]

Specify once, to keep temporary file of each task, twice to also keep the
 individual temporary file of each thread.

=cut

$opt{'keep-temporary-files+'} = \(my $opt_keep = $cfg{'keep-temporary-files'});

=item [--ignore-sr-length]

Since the pipeline is designed to use short reads for correction, it stops
 in case an average short read length above 700bp has been estimated. Set 
 C<--ignore-sr-length> to omit this test.

=cut

$opt{'ignore-sr-length'} = \(my $opt_ignore_sr_length = $cfg{'ignore-sr-length'});

=item [-h, --help]

Show this help.

=cut

$opt{'h|help'} = \(my $opt_help);

=back

=cut


##------------------------------------------------------------------------##

=head1 DEVEL OPTIONS

=cut

=over

=cut

=item [--sam=<SAM>]

Use an already created SAM file to create corrected sequences instead of 
 mapping reads to the raw pacbio reads.
 
=cut

$opt{'sam=s'} = \(my $opt_sam_file = $cfg{'sam'});

=back

=cut

##------------------------------------------------------------------------##


# parse options, test files
GetOptions(%opt) or pod2usage(1);
$opt_help && pod2usage(1);
$opt_sam_file || (@$opt_lr_file && @$opt_sr_file) || pod2usage("Either --long-reads and --short-reads or --sam required");
$opt_sam_file && ! -f $opt_sam_file && pod2usage("Cannot find $opt_sam_file");


##------------------------------------------------------------------------##
# print parameter
# 'cause I'm lazy
$V->nline;
$VS->verbose("Custom config parameter\n"
	. (Dumper(\%cfg) =~ s/^.*\n//r) =~ s/\n.*$//r) ;

$V->nline;
$VS->verbose("Command line parameter\n"
	. (Dumper(\%opt) =~ s/^.*\n//r) =~ s/\n.*$//r) ;


##------------------------------------------------------------------------##

my @sr_length;
my @sr_length_dev;
my @sr_count;
my $sr_count_total;
my $sr_qv_offset_total;
my @sr_matched;
my @sr_bps;

$VS->verbose("Checking short read files");

# short read files
foreach(@$opt_sr_file){
	-e $_ || $VS->exit("Cannot find short read file: $_");

	$V->verbose("\n".basename($_));
	
	# test if short reads are FASTQ/FASTA
	my $fp;
	my $sr_length;
	my $sr_length_dev = '0';
	my $sr_qv_offset;
	my $sr_count;
	
	# FASTQ
	if($fp = Fastq::Parser->new(file => $_)->check_format){ 
		# format
		$V->verbose("Detected FASTQ format");
		
		# length
		($sr_length, $sr_length_dev) = $fp->guess_seq_length;
		$V->verbose(sprintf("Estimated short read length: %d +-%d", $sr_length, $sr_length_dev ));
		if(!$opt_ignore_sr_length && $sr_length > 1000){
			$V->exit(
				"Estimated short reads length > 1000\n"
				."Are you sure you specified the correct data? "
				."To run the pipeline on this data, which by design is not really suited, "
				."you need to specify --ignore-sr-length"
			);
		}
		
		# offset
		unless (defined $cfg{'sr-qv-offset'}){ # manual overwrite from config
			$sr_qv_offset = $fp->guess_phred_offset; 
			$V->exit(
				"Estimating short read quality offset failed.\n"
				."See 'sr-qv-offset' in the advanced section for manual overwrite"
			) unless defined $sr_qv_offset;
			$V->verbose(sprintf("Etimated short read quality offset: %d", $sr_qv_offset));
			
			if(defined($sr_qv_offset_total)){
				$sr_qv_offset_total == $sr_qv_offset || $VB->exit('Different formats/quality offsets in short read files not allowed');
			}else{
				$sr_qv_offset_total = $sr_qv_offset;
			}
		}
		
		# count
		$sr_count = $fp->guess_seq_count();
		$V->verbose(sprintf("Estimating approximate number of short reads: %s", Verbose->Humanize($sr_count)));
	
	
	# FASTA
	}elsif($fp = Fasta::Parser->new(file=> $_)->check_format){
		# format
		$V->verbose("Detected FASTA format");

		# length		
		($sr_length, $sr_length_dev) = $fp->guess_seq_length;
		$V->verbose(sprintf("Estimating short read length: %d +-%d", $sr_length, $sr_length_dev));
		if(!$opt_ignore_sr_length && $sr_length > 1000){
			$V->exit(
				"Estimated short reads length > 1000\n"
				."Are you sure you specified the correct data? "
				."To run the pipeline on this data, which by design is not really suited, "
				."you need to specify --ignore-sr-length"
			);
		}
		
		if(defined($sr_qv_offset_total)){
			$sr_qv_offset_total == 0 || $VB->exit('Different formats/quality offsets in short read files not allowed');
		}else{
			$sr_qv_offset_total = 0;
		}

		# count
		$sr_count = $fp->guess_seq_count();
		$V->verbose(sprintf("Estimating approximate number of short reads: %s", Verbose->Humanize($sr_count)));

		
	}else{
		$V->exit("Short read file $_ neither FASTQ nor FASTA format");
	}

	# push
	push @sr_length, $sr_length;
	push @sr_length_dev, $sr_length_dev;
	push @sr_count, $sr_count;
	push @sr_bps, ($sr_count * $sr_length);
	$sr_count_total+= $sr_count;
}

$sr_qv_offset_total = $cfg{'sr-qv-offset'} unless defined $sr_qv_offset_total;

my $mean_sr_length;
$mean_sr_length += $_ for @sr_length;
$mean_sr_length /= @sr_length;

my $mean_sr_dev;
$mean_sr_dev += $_ for @sr_length_dev;
$mean_sr_dev /= @sr_length_dev;

my $min_lcr_length = $mean_sr_length + $mean_sr_dev;
$min_lcr_length += $min_lcr_length * 0.15; # add another 15 percent
$min_lcr_length = int($min_lcr_length + 0.5);


##------------------------------------------------------------------------##
# configure Sam::Seq

Sam::Seq->MaxCoverage($opt_cov);
Sam::Seq->BinSize($cfg{'bin-size'});


##------------------------------------------------------------------------##

=head1 MAIN

=cut


# globals
my $PG_line;

# mode
my @TASKS;
my $TC = -1;

if($opt_sam_file){
	$opt_mode = 'external-sam';
	@TASKS = @{$cfg{'mode-tasks'}{$opt_mode}};
}else{
	unless($opt_mode){
		if($mean_sr_length > 200){
			$opt_mode = 'pacbio-ccs';
			@TASKS = @{$cfg{'mode-tasks'}{$opt_mode}};
		}else{
			$opt_mode = 'pacbio-iterative';
			@TASKS = @{$cfg{'mode-tasks'}{$opt_mode}};
		}
	}
}



$V->nline;
$VS->verbose('Running mode: '.$opt_mode);

$opt_prefix = 'proovread' unless defined $opt_prefix;

# DEPRECATED
#unless ($opt_prefix){
#	my @time = (localtime(time))[reverse(0..5)];
#	$time[0]+=1900;
#	$time[1]++;
#	$opt_prefix = 'pr_'.sprintf("%4d-%02d-%02d_%02d-%02d-%02d", @time)
#}

# create tmp folders
my @tmp_dirs = (map{$opt_prefix."/".$_}@TASKS);
if(-e $opt_prefix){
	if(-d $opt_prefix){
		$VS->exit("Output directory already exists and is not empty")
		unless is_empty_dir($opt_prefix);
	}else{
		$VS->exit("Output directory already exists, yet is no directory")
	} 
} 

make_path($opt_prefix, @tmp_dirs);

my $LR;
my @LR_IDS;
my $lr_chunk_offsets;
my @lr_count;
my @lr_length;
my @lr_bps;
my $sr_bps_total;
my $lr_bps_total;
my $sam_chunk_offsets;
my $opt_finish_aligned_only = $cfg{'finish-aligned-only'};
my $estimated_coverage;

foreach my $task(@TASKS){
	$TC++;
	if($task eq 'read-sam'){
		# $VS->exit("task not yet implemented")
		# TODO: sam2cns w/o reference
		$LR = read_sam();
		$sam_chunk_offsets = create_sorted_sam();
		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
	}elsif($task eq 'read-long'){
		
		# long read files
		foreach(@$opt_lr_file){
			-e $_ || $VS->exit("Cannot find long read file: $_");
		}
		
		$lr_chunk_offsets = prepare_lr();
		
		# decide how to finish (realign mapped only or everything)
		unless(defined $opt_finish_aligned_only){
			# compute long-read - short-read coverage
			$lr_bps_total += $_ for @lr_bps;
			$sr_bps_total += $_ for @sr_bps;
			$estimated_coverage = sprintf("%02d", $sr_bps_total/$lr_bps_total);
			$opt_finish_aligned_only = $estimated_coverage > 100;
			$V->verbose('Estimated short-read/long-read base pair ratio: '.$estimated_coverage);
			$opt_finish_aligned_only 
				? $V->verbose('Finishing with previously aligned reads only')
				: $V->verbose('Finishing by mapping all short reads');
		}
		
		
	}elsif($task eq 'shrimp-iter-1'){

		run_shrimp(
			sr_files => $opt_sr_file,
			shrimp => {
				%{$cfg{$task}}, # basic shrimp params from cfg
				'verbose' => 1,
				'log' => task_file_name(suffix => "_shrimp.log"),
				'ref' => task_file_name('.fa', task => $TASKS[$TC-1] ),
				#'--al' => task_file_name(suffix => "_sr.fq"),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);
	
		$sam_chunk_offsets = create_sorted_sam();
		
		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);

		$LR = undef;

	}elsif($task eq 'shrimp-iter-2'){

		run_shrimp(
			sr_files => $opt_sr_file,
			shrimp => {
				%{$cfg{$task}}, # basic shrimp params from cfg
				'verbose' => 1,
				'log' => task_file_name(suffix => "_shrimp.log"),
				'ref' => task_file_name(".fm", task => $TASKS[$TC-1] ),
				#'--al' => task_file_name(suffix => "_sr.fq"),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);

		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
	
		$LR = undef;
		
	}elsif($task eq 'shrimp-ccs'){

		run_shrimp(			
			sr_files => $opt_sr_file,
			shrimp => {
				%{$cfg{$task}}, # basic shrimp params from cfg
				'verbose' => 1,
				'log' => task_file_name(suffix => "_shrimp.log"),
				'ref' => task_file_name('.fa', task => $TASKS[$TC-1] ),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);
		
		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
		$LR = undef;
		
	}elsif($task eq 'shrimp-finish'){

		my $sr_finish_files;

		if($opt_finish_aligned_only){
			my @sr_files;
			# collect all dumped short read files from previous iterations
			foreach my $task (@TASKS[1..$TC-1]){
				push @sr_files, map{
					task_file_name(task => $task, suffix=> "_sr".$_.".fq")
				}(0..$#sr_count);
			}
			$sr_finish_files = \@sr_files;
		}else{
			$sr_finish_files = $opt_sr_file;
		}
	
		
		run_shrimp(
			sr_files => $sr_finish_files,
			shrimp => {
				%{$cfg{$task}}, # basic shrimp params from cfg
				'verbose' => 1,
				'ref' => task_file_name('.fa', task => $TASKS[$TC-1] ),
				'--threads' => $opt_threads,
				'--qv-offset' => $sr_qv_offset_total,
			}
		);
		
		$sam_chunk_offsets = create_sorted_sam();

		$lr_chunk_offsets = correct_sr_mt($sam_chunk_offsets, $lr_chunk_offsets);
		
		$LR = undef;
		
	}else{
		$VB->exit("unknown task: ".$task);
	}
}



# create final output
my $opt_fa_raw = task_file_name(task => '', suffix => "_corr.raw.fa");
my $opt_fq_raw = task_file_name(task => '', suffix => "_corr.raw.fq");
my $opt_fa_fil = task_file_name(task => '', suffix => "_corr.fil.fa");
my $opt_fq_fil = task_file_name(task => '', suffix => "_corr.fil.fq");

$VS->verbose("Creating raw output sequences");

copy(task_file_name(".fa", task=>$TASKS[$TC]), $opt_fa_raw);
copy(task_file_name(".fq", task=>$TASKS[$TC]), $opt_fq_raw);

fastq_filter() if $cfg{'fastq-filter'};

# lets see if we came this far
$no_error++;

# put in END to wait for memory to be cleaned
END{
	unless ($opt_keep){
		$VS->verbose("Cleaning up");
		remove_tree(@tmp_dirs) 
	};
	if ($no_error){
		Verbose->new()->verbose("Done");
	} 
}




##------------------------------------------------------------------------##

=head1 METHODS

=cut



=head2 read_sam



=cut

sub read_sam{
	
	my %LR;
	
	# init input stream parser
	my $rsp = Sam::Parser->new(
		file => $opt_sam_file
	);
	
	# init input stream parser progess bar	
	my $pg_rsp = Verbose::ProgressBar->new(
		size => $rsp->fh
	);
	
	my $tsp = $opt_ram_sam ? undef : Sam::Parser->new(
		file => task_file_name(suffix => '_tmp.sam'),
		mode => '+>',
	);
	
	# read sam header
	
	while(my %h = $rsp->next_header_line('SQ|PG')){
		$pg_rsp->update();
		# @PG
		if($h{tag} eq '@PG'){
			$PG_line = $h{raw};
			next;
		}
		$LR{$h{'SN'}} = Sam::Seq->new(
			id => $h{SN}, 
			len => $h{LN},
			sam => $tsp,	# indexed sam file, containing aln data
		);
	}
	
	
	# read sam file
	my $rsp_c = 0;
	if($opt_ram_sam){
		while(my $aln = $rsp->next_aln()){
			# try to add aln, if sufficient score, add to temporary sam file
			$rsp_c++ if($LR{$aln->rname}->add_aln_by_score($aln));
			$pg_rsp->update() unless $rsp_c%10000;
		}
	}else{
		while(my $aln = $rsp->next_aln()){
			# try to add aln, if sufficient score, add to temporary sam file
			if($LR{$aln->rname}->add_aln_by_score($aln)){
				$rsp_c++;
				$tsp->append_aln($aln);
			};
			$pg_rsp->update() unless $rsp_c%10000;
		}
	}
	$pg_rsp->finish();
	
	@LR_IDS = sort byfile keys %LR;
	
	return \%LR;
	
}



=head2 run_shrimp

Run and process shrimp

=cut

sub run_shrimp{
	my $p = {
		sr_files => [],
		shrimp => {},
		tmp_sam => task_file_name("_tmp.sam"),
		ram_sam => $opt_ram_sam,
		@_
	};
	
	$V->nline;
	$V->nline;
	$VS->verbose("Running task ".$TASKS[$TC]);
	
	
	# Index genome file first and save projection for multiple short read
	#  files
	$VS->verbose("Indexing Long reads");
	
	# init shrimp handler
	my $shrimp_ldx = Shrimp->new( 
		%{$p->{shrimp}},
		'--save' => task_file_name("_shrimp_idx"),
		'log' => task_file_name(suffix => "_shrimp_idx.log"),
	);

	$VB->hline();
	$VB->verbose($shrimp_ldx->command());
	$VB->hline();
	
	# run shrimp
	$shrimp_ldx->run->finish;




	# init temporary sam writer
	my $tsp = $p->{ram_sam} ? undef : Sam::Parser->new(
		file => $p->{tmp_sam},
		mode => '+>',
	);


	my $sr_file_c = 0;
	my $pg_rsp;
	my $pg_step;
	
	### foreach sr file read mappings	
	foreach my $sr_file (@{$p->{sr_files}}){

		# init input stream parser progess bar	
		if($TASKS[$TC] eq 'shrimp-finish' && $opt_finish_aligned_only){
			$pg_rsp = Verbose::ProgressBar->new(size => $sr_matched[$sr_file_c]);
			$pg_step = int(($sr_matched[$sr_file_c]/10000)+0.5) || 1; # never be zero
		}else{
			$pg_rsp = Verbose::ProgressBar->new(size => $sr_count[$sr_file_c]);
			$pg_step = int(($sr_count[$sr_file_c]/10000)+0.5) || 1; # never be zero
		}
		
		$VS->verbose("Mapping short reads $sr_file");

		# init shrimp handler
		my $shrimp = Shrimp->new( 
			%{$p->{shrimp}},
			'ref' => undef,
			'reads' => $sr_file,
			'log' => task_file_name("_shrimp_sr".$sr_file_c.".log"),
			'--progress' => $pg_step,
			'--load' => task_file_name("_shrimp_idx"),
			'-s' => undef, # cannot specify seeds when loading genome
			$opt_finish_aligned_only && $TASKS[$TC] ne 'shrimp-finish'
				? ('--al' => task_file_name(suffix => "_sr".$sr_file_c.".fq"))
				: (),
		);
	
		$VB->hline();
		$VB->verbose($shrimp->command());
		$VB->hline();
		
		# run shrimp
		$shrimp->run;
	
		# init input stream parser
		my $rsp = Sam::Parser->new(
			fh => $shrimp->oh
		);
		
		# read the header and create $LR only on first short read file
		if($sr_file_c == 0){
			# read SAM header
			while(my %h = $rsp->next_header_line('SQ|PG')){
				# @PG
				if($h{tag} eq '@PG'){
					$PG_line = $h{raw};
					next;
				}
				$LR->{$h{'SN'}} = Sam::Seq->new(
					id => $h{SN}, 
					len => $h{LN},
					sam => $tsp,	# indexed sam file, containing aln data
				);
			}
		
			$PG_line = '@PG ID:unknown' unless $PG_line;
		}
	
		# read SAM alignmetn section
		my $rsp_c = 0;
		my $add_c = 0;
		my $src_lib_sum = 0;
		my $src;
		# shrimp log
		my $slh = $shrimp->logh;
		
		if($p->{ram_sam}){
			while(my $aln = $rsp->next_aln()){
				# try to add aln
				$add_c++ if($LR->{$aln->rname}->add_aln_by_score($aln));
				# monitor shrimp progress
				unless($rsp_c% $pg_step){
					seek($slh, -50, 2); # get, ..
					read($slh, my $tail, 50); # .. read, .. 
					# .. and parse last 50 chars of shrimp log for number of processed reads
					($src) = $tail =~ /(\d+)\s+\S+\s+\S+\s*$/;
					$pg_rsp->update($src) if defined $src; 
				}
				$rsp_c++;
			}
			
			seek($slh, -1500, 2); # get, ..
			read($slh, my $tail, 1500); # .. read, .. 
			# .. and parse last 1500 chars of shrimp log for number of processed reads
			my ($reads_matched) = $tail =~ /Reads Matched:\s+(\S+)/;
			$reads_matched =~ tr/,//d;
			push @sr_matched, $reads_matched;

		}else{ # create tmp sam
			while(my $aln = $rsp->next_aln()){
				# try to add aln, if sufficient score, add to temporary sam file
				if($LR->{$aln->rname}->add_aln_by_score($aln)){
					$add_c++; 
					$tsp->append_aln($aln);
				};
				# monitor shrimp progress
				unless($rsp_c% $pg_step){
					seek($slh, -50, 2); # get, ..
					read($slh, my $tail, 50); # .. read, .. 
					# .. and parse last 50 chars of shrimp log for number of processed reads
					($src) = $tail =~ /(\d+)\s+\S+\s+\S+\s*$/;
					$pg_rsp->update($src) if defined $src; 
				}
				$rsp_c++;
			}

			seek($slh, -1500, 2); # get, ..
			read($slh, my $tail, 1500); # .. read, .. 
			# .. and parse last 1500 chars of shrimp log for number of processed reads
			my ($reads_matched) = $tail =~ /Reads Matched:\s+(\S+)/;
			$reads_matched =~ tr/,//d;
			push @sr_matched, $reads_matched;
		}


		# get final short read count of this file
		if($TASKS[$TC] eq 'shrimp-finish' && $opt_finish_aligned_only){
			$pg_rsp->finish($sr_matched[$sr_file_c]);
		}else{
			$pg_rsp->finish($sr_count[$sr_file_c]);
		}

		# finish shrimp run
		$shrimp->finish;
		$sr_file_c++;
	}

#	$pg_rsp->finish($sr_count_total);
	
}


=head2 create_sorted_sam

=cut

sub create_sorted_sam{
	my $opt_sam_out = task_file_name(".sam");
	
	$V->nline;
	$VS->verbose("Creating filtered sam ".$opt_sam_out);
	
	open(OUT, '>',$opt_sam_out) or $VB->exit($!);
	
	# header section
	printf OUT ("\@HD\tVN:%s\tSO:%s\n", "unknown", "unknown");
	foreach my $pb_id (@LR_IDS){
		unless (defined $LR->{$pb_id}){
			die $pb_id;
		}
		printf OUT ("\@SQ\tSN:%s\tLN:%s\n", $pb_id, $LR->{$pb_id}->len);
	}
	
	# header @PG
	print OUT $PG_line;
	
	# init input stream parser progess bar	
	my $pgb = Verbose::ProgressBar->new(size => scalar @LR_IDS);
	
	my @chunk_idxs;
	# alignment section
	my $pb_c = 0;
	foreach my $pb_id (@LR_IDS){
		push @chunk_idxs, tell(OUT) unless $pb_c % $cfg{'chunk-size'};

		foreach my $aln($LR->{$pb_id}->alns($opt_sort_sam_by_coords)){
			# write to sam
			print OUT $aln->raw;
			# write to LR wise FASTQ
		}
		$pgb->update($pb_c);
		$pb_c++;
	}
	$pgb->finish($pb_c);
	
	close OUT;
	
	return \@chunk_idxs;
}




=head2 prepare_lr

Read the pacbio long read file and create a new, indexed long read file,
 ordered the same way as the sorted sam files.

=cut

sub prepare_lr{

	$V->nline;
	$VS->verbose("Preparing long reads");

	# read fasta/fastq, write and sort by id
	my %lr;

	my $lrpw = Fasta::Parser->new( 
		file => task_file_name(".fa", task => $TASKS[$TC] ), 
		mode => '+>'
	);

	foreach(@$opt_lr_file){
		
		my $lrpr;
		$lrpr = Fasta::Parser->new(file => $_)->check_format();
		$lrpr = Fastq::Parser->new(file => $_)->check_format() unless $lrpr;
		$lrpr || $VS->exit("Unknown format in '--long-read' file: ".$_);
	
		my $lr_count = $lrpr->guess_seq_count();
		push @lr_count, $lr_count;
		my ($lr_length, $lr_dev) =  $lrpr->guess_seq_length;
		push @lr_length, $lr_length;
		push @lr_bps, ($lr_length * $lr_count);
		
	
		if(ref $lrpr eq 'Fasta::Parser'){
			while(my $lr = $lrpr->next_seq){
				if(exists $lr{$lr->id}){
					$VS->exit('Non-unique long read id ('. $lr->id .') in '. $_);
				}
				$lr->seq(lc($lr->seq())); # convert seq to lower case
				$lr{$lr->id} = $lr;
			}
		}else{
			while(my $lr = $lrpr->next_seq){
				if(exists $lr{$lr->id}){
					$VS->exit('Non-unique long read id ('. $lr->id .') in '. $_);
				}
				# convert FASTQ to FASTA
				$lr{$lr->id} = Fasta::Seq->new(
					id => $lr->id,
					desc => $lr->desc,
					seq => lc($lr->seq), # convert seq to lower case
				);
			}
		}
		
		
	}

	# write sorted/indexed fq/fa lr file for pbc
	my @lr_idxs;
	my $lr_c = 0;
	@LR_IDS = sort byfile keys %lr;
	foreach(@LR_IDS){
		my $pos = $lrpw->append_seq($lr{$_});
		push @lr_idxs, $pos unless $lr_c % $cfg{'chunk-size'};
		$lr_c++;
	}
	return \@lr_idxs;
}



=head2 correct_sr_mt

=cut

sub correct_sr_mt{
	my ($sam_chunk_offsets, $lr_chunk_offsets) = @_;
	
	$V->nline;
	$VS->verbose("Correcting Sequences (".@$sam_chunk_offsets." batches)");
	
	# pbc_correct.pl 
	my %pbc_default = (
		'--sam' 		=> task_file_name(".sam"),
		'--max-reads'	=> $cfg{'chunk-size'},
		'--coverage'	=> $opt_cov,
		'--append'		=> 1,
		$opt_mode eq 'external-sam' # no ref
			? ()
			: ('--ref' 		=> $TC == 1
						 	 ? task_file_name(".f[aq]", task => $TASKS[$TC-1] )
						 	 : task_file_name(".fq", task => $TASKS[$TC-1] )),
		$TASKS[$TC] eq 'shrimp-iter-1' # calculate hcrs on first iter for second iter
			? ('--min-lcr-length' => $min_lcr_length) # params from config
			: ('--min-hcr-length' => 0),
		$TASKS[$TC] eq 'shrimp-finish' # calculate hcrs on first iter for second iter
			? ('--ignore-hcr' => 1, $cfg{'detect-chimera'} ? ('--detect-chimera' => 1) : ()) # params from config
			: (),
		$cfg
		 	? ('--cfg'	=> $cfg) 
		 	: (),
	);
	
	my $pbc_cmds = '';
	
	# generate xargs statements foreach chunk
	for(my $ci=0; $ci<@$sam_chunk_offsets; $ci++){
		my %pbc_config = (
			%pbc_default,
			'--prefix'		=> task_file_name(".".$ci),
			'--sam-offset' => $sam_chunk_offsets->[$ci], 
			'--ref-offset' => $lr_chunk_offsets->[$ci],
		);
		
		# params
		$pbc_cmds.= param_join(\%pbc_config)."\n";
	}
	
	# write cmd file
	
	my $cfg_file = task_file_name(".cmds");
	open(CFG, '>', $cfg_file) or $VS->exit($!);
	print CFG $pbc_cmds;
	close CFG;
	
	# xarg cmds, capture stderr;
	my $xgr;
	open($xgr, "(xargs --arg-file $cfg_file --max-procs $opt_threads -L 1 --verbose perl $RealBin/sam2cns) 2>&1 |")
		or $VS->exit($!);
	
	$VB->hline();
	# 
	my $bc;
	my $bs = "Batch %d/".@$sam_chunk_offsets;
	while(<$xgr>){
		chomp();
		if ($_ =~ /^perl /){
			$VS->verbose(sprintf($bs, ++$bc));
			$VB->verbose($_);
			$VB->hline() 
		}else{
			$VB->verbose($_);
		}
		
		if(/xargs:.*255/){
			$VS->exit("sam2cns returned with error");
		}
	}
	
	
	$VS->verbose("Merging corrected output");
	my $fq_file = task_file_name(".fq");
	my $fq_glob = task_file_name(".[0-9]*.fq");
	my $fa_file = task_file_name(".fa");
	my $fa_glob = task_file_name(".[0-9]*.fa");
	my $fm_file = task_file_name(".fm");
	my $fm_glob = task_file_name(".[0-9]*.fm");
	my $fc_file = task_file_name(".fc");
	my $fc_glob = task_file_name(".[0-9]*.fc");
	
	my @fq_glob = sort byfile glob $fq_glob;
	my @fa_glob = sort byfile glob $fa_glob;
	my @fm_glob = sort byfile glob $fm_glob;
	my @fc_glob = sort byfile glob $fc_glob;
	my $fq_glob_sorted = join(" ", @fq_glob);
	my $fa_glob_sorted = join(" ", @fa_glob);
	my $fm_glob_sorted = join(" ", @fm_glob);
	my $fc_glob_sorted = join(" ", @fc_glob);
	
	# create offset idx for reference
	my @ref_idxs = (0);
	my $offset = 0;
	# get fq indexes
	foreach(@fq_glob){
		$offset+= -s $_;
		push @ref_idxs, $offset;   
	}
	
	# remove last on, its just the eof
	pop(@ref_idxs);
	
	qx(cat $fq_glob_sorted > $fq_file);
	qx(cat $fa_glob_sorted > $fa_file);
	qx(cat $fm_glob_sorted > $fm_file);
	qx(cat $fc_glob_sorted > $fc_file);
	
	unlink @fq_glob unless $opt_keep > 1;
	unlink @fa_glob unless $opt_keep > 1;
	unlink @fm_glob unless $opt_keep > 1;
	unlink @fc_glob unless $opt_keep > 1;
	
	return \@ref_idxs;
}

=head2 file_name

Create a file name depending on current $TC and $opt_prefix

  $TC = 1;
  $opt_prefix = "/foo";
  task_file_name(".suf"); # $TASKS[$TC]
    # "/foo_shrimp-iter-1.suf"
  task_file_name(".suf", prefix => "/foo/bar", task => 'custom');
    # "/foo_custom/bar_custom.suf"

=cut


sub task_file_name{
	my $p = {
		root => $opt_prefix,
		task => $TASKS[$TC],
		prefix => $opt_prefix,
		suffix => (@_%2 ? shift : ''),
		@_
	};
	
	return sprintf('%1$s/%2$s/%3$s%4$s', $p->{root}, $p->{task}, $p->{prefix}, $p->{suffix});
}


=head2 create_custom_cfg

=cut

sub copy_custom_cfg{
	my ($cfg_core_file, $cfg_custom_file) = @_;	
	open(COR, $cfg_core_file) or $VS->exit($!);
	open(CUS,'>',$cfg_custom_file) or $VS->exit("Couldn't create config file: $cfg_custom_file");
	
	while(<COR>){
		if(/^#/){
			next unless /^##/; 
			print CUS $_;
		}else{
			if(/^\s*$/){
				print CUS $_;
			}else{
				print CUS '#',$_; 
			}
		}
	}
	
	close COR;
	close CUS;		
}


=head2 fastq_filter

Run FastqFilter.pl on raw output

=cut

sub fastq_filter{

	my $params = param_join(\%{$cfg{'fastq-filter'}});

	my $cmd_fa_fil = "$RealBin/FastqFilter.pl $params --in $opt_fq_raw --fasta --out $opt_fa_fil\n";
	my $cmd_fq_fil = "$RealBin/FastqFilter.pl $params --in $opt_fq_raw --out $opt_fq_fil\n";
	
	$V->nline;
	$VS->verbose("Quality trimming raw output");
	$VB->hline;
	$VB->verbose($cmd_fa_fil);
	qx($cmd_fa_fil);
	
	$VB->hline;
	$VB->verbose($cmd_fq_fil);
	qx($cmd_fq_fil);
	
}

=head2 byfile

Sort function for "natural" filesorting, descending.

=cut

sub byfile {
  my @a = split /(\d+)/, $a;
  my @b = split /(\d+)/, $b;
  my $M = @a > @b ? @a : @b;
  my $res = 0;
  for (my $i = 0; $i < $M; $i++) {
    return -1 if ! defined $a[$i];
    return 1 if  ! defined $b[$i];
    if ($a[$i] =~ /\d/) {
      $res = $a[$i] <=> $b[$i];
    } else {
      $res = $a[$i] cmp $b[$i];
    }
    last if $res;
  }
  $res;
}

=head2 is_empty_dir

Check whether a folder contains any files.

=cut

sub is_empty_dir {
    my $dirname = shift;
    opendir(my $dh, $dirname) or die "Not a directory";
    return scalar(grep { $_ ne "." && $_ ne ".." } readdir($dh)) == 0;
}


=head2 param_join (HASHREF, JOIN=STRING)

Joins a HASHREF to a parameter string with JOIN [" "], ignoring keys with 
 undef values and creating flag only values for ''.

  param_join(HASHREF); # join with space
  param_join(HASHREF, join => "\n") # join with newline

=cut

sub param_join{
	my %params = %{shift @_};
	my $p = {
		'join' => " ",
		@_
	};
	
	# params
	my @params;
	my $params;
	foreach my $k (sort keys %params){
		my $v = $params{$k};
		# flag only is '', NOT '0' !!!
		next unless defined ($v);
		push @params, ($v ne '') ? ($k, $v) : $k;
	}
	$params .= join($p->{'join'}, @params);
	return $params;
}


################
## DEPRECATED ##
################

=pod

#=head2 correct_sr_st
#=cut
#

sub correct_sr_st{
	my ($ref, $sam_out) = @_;
	
	# pbc_correct.pl 
	my %pbc_default = (
		'--sam' 		=> $sam_out,
		'--coverage'	=> $opt_cov,
		'--ref' 		=> undef,
		'--prefix'		=> undef,
		'--ignore-hcr'	=> 1,
		'--append'		=> 1,
		$cfg
		 	? ('--cfg'	=> $cfg) 
		 	: (),
	);
	
	my @pbc_keys = sort keys %pbc_default;
	
	my $pbc_cmds = '';
	
	# generate cmd foreach chunk
	my %pbc_config = (
		%pbc_default,
		'--prefix'		=> task_file_name(".".threads->tid()),
		'--ref' 		=> $ref,
	);
	
	# params
	my @pbc_cmd;
	foreach my $k (@pbc_keys){
		my $v = $pbc_config{$k};
		# flag only is undef or '', NOT '0' !!!
		push @pbc_cmd, (defined($v) && $v ne '') ? ($k, $v) : $k;
	}
	$pbc_cmds = sprintf("perl $RealBin/sam2cns %s |",  join(" ", @pbc_cmd));
	
	$VB->hline;
	$VB->verbose($pbc_cmds);
	
	my $xgr;
	open($xgr, $pbc_cmds)
		or $VB->exit($!);
	
}



#=head2 coverage_tables
#
#=cut

sub coverage_tables{
	my $opt_fq_out = task_file_name("fq");
	
	# progess bar	
	my $pgp = Verbose::ProgressBar->new(
		size => scalar keys %$LR
	);

	$VB->verbose("Calculating exact coverage by score tables ".$opt_fq_out);

	my $i=1;
	while(my ($pb_id, $pb) = each %$LR){
		my @COV;
		my $ofh;
		if($opt_fq_out eq '-'){
			$ofh = \*STDOUT;
		}else{
			open($ofh, '>', task_file_name('_'.$i.'.tsv')) or $VB->exit($!);
		}
		foreach my $score_co(1..1000){
			$pb->is(sub{ 
				my $score = $_[0]->opt('AS');
				return $score == $score_co
			});
			# add to previous cov
			push @COV, [$pb->coverage];
		}
		print $ofh join("\t", @$_)."\n" for @COV;
		close $ofh if $opt_fq_out ne '-';
		
		$pgp->update($i++);
	}
	$pgp->finish($i);


	#printf $ofh ("\@%s\n%s\n+\n%s\n", $pb->consensus);
	#my @cov = $pb->coverage;
	#my @cov1 = grep{defined($_) && $_>0}@cov;
	#
	#print "#"x30, "\n";
	#printf "%-8s %6.1f\n", 'Score:', $score_co; 
	#next unless @cov;
	##printf join(" ", @cov), "\n";
	#printf "%-8s %6.1f%%\n", 'Covered:', (@cov1/$pb->len)*100,
	#printf "%-8s %6.1f\n", 'Mean:', sum(@cov)/@cov;
	#printf "%-8s %6.1f\n", 'Max:', max(@cov);
	#printf "%-8s %6.1f\n", 'Cols:', scalar @cov;

}


=cut





##------------------------------------------------------------------------##

=head1 AUTHORS

=over

=item * Thomas Hackl, thomas.hackl@uni-wuerzburg.de

=back
